{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicabilidad en Inteligencia Artificial\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "Debido al incremento exponencial del desarrollo y la integración de sistemas inteligentes en actividades de diversa naturaleza y frecuencia, la comprensión de su funcionamiento resulta fundamental por diversos motivos. \n",
    "En primer lugar si un modelo pretende **desempeñar un papel fundamental como una herramienta para ayudar a la toma de decisiones**, su modo de razonamiento debe ser fácilmente entendible por un ser humano tradicional. Así se puede analizar su **comportamiento** para observar rasgos indeseados que poder corregir, asegurar que sus pilares se encuentran alineados con los objetivos del problema que aborda, que cumple una determinada **ética** establecida en torno a las soluciones que propone, además de medidas de seguridad críticas con las que controlar la **calidad** de las mismas. \n",
    "\n",
    "De este modo en este notebook se pretende aplicar distintas técnicas de explicabilidad con la que comprender más detalladamente la conducta característica de los clasificadores elaborados para la detección de textos sexistas.\n",
    "\n",
    "### 1.1. Tipos de explicabilidad\n",
    "\n",
    "* **Modelos agnósticos locales**. Esta categoría de técnicas se pueden emplear sobre cualquier tipo de modelo de caja negra aunque únicamente se centran en una sola muestra."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estructura del notebook\n",
    "\n",
    "1. Introducción a la Explicabilidad en Inteligencia Artificial\n",
    "2. Estructura del notebook\n",
    "3. Instalación y carga de librerías\n",
    "4. Lectura y carga de datos procesados\n",
    "5. Técnicas de explicabilidad\n",
    "6. Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instalación y carga de librerías\n",
    "\n",
    "Este apartado tiene como único propósito cargar las librerías y dependencias necesarias para la ejecución de este notebook, así como las funciones propiamente desarrolladas. Previo a ello deberán ser instaladas bien ejecutando el script *setup.sh* mediante el comando `bash setup.sh` con permisos de ejecución en distribuciones Linux, o bien ejecutando el compando `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Import encoding functions\n",
    "from encoding import *\n",
    "\n",
    "# pandas: to read the datasets\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: to work with predicted probabilities\n",
    "import numpy as np\n",
    "\n",
    "# skelearn: to encode documents\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# pickle: to load Logistic Regression models\n",
    "import pickle \n",
    "\n",
    "# lime: to create local explanations\n",
    "import lime\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# random: to choose random samples\n",
    "from random import randrange"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lectura y carga de datos procesados\n",
    "\n",
    "En esta sección se pretende leer y cargar los datos de entrenamiento y test ya procesados a los que se les ha aplicado las siguientes técnicas de tratamiento de documentos:\n",
    "\n",
    "  - Elimina URLs.\n",
    "  - Elimina usuarios mencionados.\n",
    "  - Elimina caracteres especiales, no alfabéticos y signos de puntuación.\n",
    "  - Convierte todos los caracteres en minúsculas.\n",
    "\n",
    "Tal y como se puede comprobar en los siguientes resultados las dimensiones de sendos conjuntos de datos se detallan a continuación:\n",
    "\n",
    "* Conjunto de entrenamiento: **6.865 muestras**.\n",
    "* Conjunto de validación: **4.296 muestras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset dimensions: (6865, 6)\n",
      "Test dataset dimensions: (4296, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read already processed EXIST datasets\n",
    "train_df = pd.read_csv('../data/proc_EXIST2021_train.csv')\n",
    "test_df = pd.read_csv('../data/proc_EXIST2021_test.csv')\n",
    "\n",
    "# Show the dimensions of the datasets\n",
    "print('Train dataset dimensions:', train_df.shape)\n",
    "print('Test dataset dimensions:', test_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Técnicas de explicabilidad\n",
    "\n",
    "### 5.1. LIME\n",
    "\n",
    "Se trata de un procedimiento que genera **explicaciones locales a una única muestra dentro de una determinada clase** cuyo objetivo consiste en determinar la relevancia de cada característica (palabra) proporcionada para su predicción. Para ello genera un **modelo lineal** que se entrena en base a perturbaciones generadas a partir de un ejemplo seleccionado y luego es evaluado dependiendo de la similitud entre las predicciones producidas y la real asociada a la entrada suministrada. Esta tarea es posible mediante el uso de la librería *lime* de Python a la que se le debe proporcionar una muestra de ejemplo junto con una función que permite obtener la predicción de las perturbaciones creadas.\n",
    "\n",
    "#### 5.1.1. Modelo inglés de Regresión Logística\n",
    "\n",
    "Comenzamos ejecutando este método sobre el mejor clasificador inglés de Regresión Logística encontrado cuya codificación se realizó transformando los textos en bolsas de palabras. Puesto que se trata de un método local a un ejemplo, se propone su aplicación en los conjuntos de **falsos positivos y negativos** analizados en notebooks anteriores con la idea de comprobar cuáles son los términos destacables que han liderado hacia una clasificación errónea. Como el volumen de ambos es bastante considerable tal y como se anuncia en los resultados anteriores, con 213 y 438 muestras, nos apoyaremos en los estudios efectuados en función de los intervalos de confianza para seleccionar **diez ejemplos de cada rango de forma aleatoria**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false negatives: 438\n",
      "No. of false positives: 213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8388/2998631689.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_classes'] = en_lr_model.predict(X=en_test_bag_words)\n",
      "/tmp/ipykernel_8388/2998631689.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_probs'] = [max(prob) for prob in en_lr_model.predict_proba(X=en_test_bag_words)]\n"
     ]
    }
   ],
   "source": [
    "# Load a Logistic Regression model specialized in English\n",
    "en_lr_model = pickle.load(open('../models/multileng_lr_models/en_bag_words_model.sav', 'rb'))\n",
    "\n",
    "# Filter the train documents by language\n",
    "en_train_df = train_df[train_df['language'] == 'en']\n",
    "en_train_texts = list(en_train_df['clean_text'].values)\n",
    "\n",
    "# Filter the test documents by language\n",
    "en_test_df = test_df[test_df['language'] == 'en']\n",
    "en_test_texts = list(en_test_df['clean_text'].values)\n",
    "\n",
    "# Convert train and test documents to bag of words\n",
    "en_train_bag_words, en_test_bag_words = to_bag_of_words(\n",
    "    train_docs=en_train_texts, \n",
    "    test_docs=en_test_texts)\n",
    "\n",
    "# Predict over the test dataset\n",
    "en_test_df['task1_pred_classes'] = en_lr_model.predict(X=en_test_bag_words)\n",
    "en_test_df['task1_pred_probs'] = [max(prob) for prob in en_lr_model.predict_proba(X=en_test_bag_words)]\n",
    "\n",
    "# Get the indexes of the false negatives and positives\n",
    "en_fn_df = en_test_df[(en_test_df['task1'] == 1) & (en_test_df['task1_pred_classes'] == 0)]\n",
    "en_fp_df = en_test_df[(en_test_df['task1'] == 0) & (en_test_df['task1_pred_classes'] == 1)]\n",
    "\n",
    "print(f'No. of false negatives: {en_fn_df.shape[0]}')\n",
    "print(f'No. of false positives: {en_fp_df.shape[0]}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las conclusiones extraídas de la generación de explicaciones locales a un subconjunto de **falsos negativos** se presentan a continuación:\n",
    "\n",
    "* Los falsos negativos pertenecientes al más elevado intervalo de confianza otorga un grado de **no-sexismo a palabras sin significado** como pronombres, determinantes, preposiciones y verbos auxiliares, que pueden contrarrestar el efecto de terminología sexista. \n",
    "\n",
    "* Aquellos cometidos bajo un rango de confianza alto demuestran un notable grado de **ironía** con terminología positiva aunque con significados profundamente sexistas.\n",
    "\n",
    "* Finalmente los falsos negativos que se encuentran dentro del intervalo moderado de confianza están caracterizados por su alta composición de **hashtags y errores ortográficos** que dificultan su análisis e identificación automáticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LIME explainer object\n",
    "lime_explainer = LimeTextExplainer(class_names={\n",
    "    0: 'non-sexist',\n",
    "    1: 'sexist'\n",
    "})\n",
    "\n",
    "for pair in [(0.4, 0.6), (0.6, 0.8), (0.8, 1.1)]:\n",
    "    # Filter the false negatives by confidence interval\n",
    "    en_fn_subdf = en_fn_df[(en_fn_df['task1_pred_probs'] >= pair[0]) & \\\n",
    "        (en_fn_df['task1_pred_probs'] < pair[1])]\n",
    "    en_fn_subdf_texts = list(en_fn_subdf['clean_text'].values)\n",
    "\n",
    "    # Choose 10 distinct samples randomly\n",
    "    chosen_fn_texts = []\n",
    "    for iter in range(0, 10):\n",
    "        fn_index = randrange(len(en_fn_subdf_texts))\n",
    "        while (fn_index in chosen_fn_texts):\n",
    "            fn_index = randrange(len(en_fn_subdf_texts))\n",
    "\n",
    "        chosen_fn_texts.append(fn_index)\n",
    "\n",
    "    # Create explanations for each sample\n",
    "    def predict_en_lrm_model(sample: str):\n",
    "\n",
    "        # Train a CountVectorizer object based on train documents\n",
    "        bg_vectorizer = CountVectorizer()\n",
    "        bg_vectorizer.fit(raw_documents=en_train_texts)\n",
    "\n",
    "        # Encode the provided test sample \n",
    "        encoded_sample = bg_vectorizer.transform(raw_documents=sample).toarray()\n",
    "        \n",
    "        # Predict the probabilities for both classes\n",
    "        pred_prob = en_lr_model.predict_proba(X=encoded_sample)\n",
    "        return np.array(pred_prob)\n",
    "\n",
    "    for indx in chosen_fn_texts:\n",
    "        # Create a single explanation for a single test sample\n",
    "        lime_explanation = lime_explainer.explain_instance(\n",
    "            en_fn_subdf_texts[indx], \n",
    "            predict_en_lrm_model).show_in_notebook(text=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicando el mismo procedimiento anterior aunque aplicado a los **falsos positivos** se han podido descubrir las siguientes pesquisas:\n",
    "\n",
    "* Los falsos positivos de los dos intervalos superiores de confianza **contienen noticias y reivindaciones de usuarios contra los ataques y la violencia contra la mujer**. No obstante, términos comunes como \"mujeres\", \"feminismo\", etc. son catalogados como sexistas y por ende se han categorizado bajo esta clase erróneamente.\n",
    "\n",
    "* Los falsos positivos situados en el intervalo moderado de confianza destacan por tratar **otros tópicos** en los que aparecen también palabras de género como \"mujeres\", \"marido\", entre otras que pese a ser clasificadas como sexistas su significado no es tal. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1. Modelo español de Regresión Logística\n",
    "\n",
    "A continuación se repite el estudio previo pero haciendo uso del mejor modelo español de Regresión Logística con sus correspondientes documentos en dicho idioma. En los siguientes resultados se puede apreciar que existen 462 documentos sexistas no detectados y 199 textos no sexistas erróneamente clasificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false negatives: 462\n",
      "No. of false positives: 199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8388/1758952928.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  es_test_df['task1_pred_classes'] = es_lr_model.predict(X=es_test_bag_words)\n",
      "/tmp/ipykernel_8388/1758952928.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  es_test_df['task1_pred_probs'] = [max(prob) for prob in es_lr_model.predict_proba(X=es_test_bag_words)]\n"
     ]
    }
   ],
   "source": [
    "# Load a Logistic Regression model specialized in Spanish\n",
    "es_lr_model = pickle.load(open('../models/multileng_lr_models/es_bag_words_model.sav', 'rb'))\n",
    "\n",
    "# Filter the train documents by language\n",
    "es_train_df = train_df[train_df['language'] == 'es']\n",
    "es_train_texts = list(es_train_df['clean_text'].values)\n",
    "\n",
    "# Filter the test documents by language\n",
    "es_test_df = test_df[test_df['language'] == 'es']\n",
    "es_test_texts = list(es_test_df['clean_text'].values)\n",
    "\n",
    "# Convert train and test documents to bag of words\n",
    "es_train_bag_words, es_test_bag_words = to_bag_of_words(\n",
    "    train_docs=es_train_texts, \n",
    "    test_docs=es_test_texts)\n",
    "\n",
    "# Predict over the test dataset\n",
    "es_test_df['task1_pred_classes'] = es_lr_model.predict(X=es_test_bag_words)\n",
    "es_test_df['task1_pred_probs'] = [max(prob) for prob in es_lr_model.predict_proba(X=es_test_bag_words)]\n",
    "\n",
    "# Get the indexes of the false negatives and positives\n",
    "es_fn_df = es_test_df[(es_test_df['task1'] == 1) & (es_test_df['task1_pred_classes'] == 0)]\n",
    "es_fp_df = es_test_df[(es_test_df['task1'] == 0) & (es_test_df['task1_pred_classes'] == 1)]\n",
    "\n",
    "print(f'No. of false negatives: {es_fn_df.shape[0]}')\n",
    "print(f'No. of false positives: {es_fp_df.shape[0]}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las deducciones descubiertas tras la visualización de diez muestras positivas clasificadas erróneamente seleccionadas aleatoriamente por cada intervalo de confianza, como se ha efectuado con el clasificador inglés, han sido idénticamente similares a las observadas previamente.\n",
    "\n",
    "Por otro lado en relación a los falsos positivos, es decir ejemplos negativos identificados como positivos, además de compartir las características descubiertas anteriormente también cabe destacar la **sexualización por parte del modelo de prendas femeninas**, como la falda, además de la no comprensión de terminología latinoamericana puesto que no se les asigna ninguna clase o valor por lo que se consideran neutros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

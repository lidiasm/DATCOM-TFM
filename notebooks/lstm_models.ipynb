{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos LSTM\n",
    "\n",
    "## 1. Introducción a LSTM\n",
    "\n",
    "LSTM es un acrónimo de *Long-Short Term Memory* y representa a un **subtipo de RNN** (*Recurrent Neural Network*) capaz de **retener información relevante** sobre datos ya procesados que ayude al procesamiento de nuevas secuencias de datos completas. Su arquitectura se encuentra compuesta a su vez por tres redes neuronales:\n",
    "\n",
    "* ***Forget Gate***: este primer modelo es el encargado de filtrar qué información previa es útil para su almacenamiento y qué datos ya no son útiles para futuras iteraciones. \n",
    "\n",
    "* ***Input Gate***: esta segunda red trata de determinar el valor que presentan los datos entrantes para resolver la tarea de clasificación.\n",
    "\n",
    "* ***Output Gate***: finalmente esta red calcula las salidas del modelo LSTM que dependerán de la tarea de clasificación que se pretende abordar.\n",
    "\n",
    "### 1.1. Condiciones de uso\n",
    "\n",
    "Dependiendo del framework que se pretenda utilizar (Tensorflow, Keras, Pytorch) existen diferentes tratamientos de datos y requisitos de implementación que se deben cumplir al definir la arquitectura, entrenamiento y validación de modelos. En mi caso particular he optado por utilizar **Keras** debido a la experiencia previa que tengo con la librería y a su facilidad de uso. \n",
    "\n",
    "1. **Procesamiento y limpieza** de los documentos.\n",
    "\n",
    "2. **Tokenización** de los documentos especificando un token para aquellos términos que no sean reconocidos dentro de un vocabulario de palabras.\n",
    "\n",
    "3. **Codificación** numérica en forma de matrices secuenciales de valores. \n",
    "\n",
    "5. **Normalización** de las secuencias numéricas para establecer un mismo tamaño fijo, completando con ceros aquellas de menor longitud y separando en varias secuencias aquellas que dispongan de un mayor tamaño.\n",
    "\n",
    "6. Definición de la arquitectura de un **modelo** e instanciación para su posterior entrenamiento y validación.\n",
    "\n",
    "### 1.2. Casos de uso\n",
    "\n",
    "* Detección y extracción de patrones en secuencias de datos.\n",
    "* Modelado del lenguaje natural.\n",
    "* Traducción de texto.\n",
    "* Reconocimiento de textos manuscritos.\n",
    "* Generación de imágenes mediante mecanismos de atención.\n",
    "* Sistemas de preguntas y respuestas.\n",
    "* Conversión de vídeo a texto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estructura del notebook\n",
    "\n",
    "1. Introducción a LSTM\n",
    "2. Estructura del notebook\n",
    "3. Instalación y carga de librerías\n",
    "4. Lectura y carga de datos\n",
    "5. Experimentos y modelos\n",
    "6. Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instalación y carga de librerías\n",
    "\n",
    "Este apartado tiene como único propósito cargar las librerías y dependencias necesarias para la ejecución de este notebook, así como las funciones propiamente desarrolladas. Previo a ello deberán ser instaladas bien ejecutando el script *setup.sh* mediante el comando `bash setup.sh` con permisos de ejecución en distribuciones Linux, o bien ejecutando el compando `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 14:10:36.165320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 14:10:36.628511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-05 14:10:36.628590: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-05 14:10:37.794184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 14:10:37.794414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 14:10:37.794431: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-05 14:10:40.434246: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-05 14:10:40.434480: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-05 14:10:40.434497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lidiasm): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "# Import data read and compute functions\n",
    "from data import read_train_dataset, read_test_dataset\n",
    "\n",
    "# Import text preprocess functions\n",
    "from processing import *\n",
    "\n",
    "# numpy: to work with numeric codifications and embeddings\n",
    "import numpy as np\n",
    "\n",
    "# keras: to define and build LSTM models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import LSTM, Activation, Dense, Input, Embedding\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# sklearn: to plot a confusion matrix per trained model\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# matplotlib: to plot charts\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lectura y carga de datos originales\n",
    "\n",
    "En esta sección se pretende **cargar los datasets de entrenamiento y validación** procedentes de los correspondientes ficheros situados en la carpeta *data*. Al tener un **formato TSV** se deben leer como tablas aunque posteriormente se trabaje con ellos en formato *dataframe*. \n",
    "\n",
    "Tal y como se puede comprobar en los siguientes resultados las dimensiones de sendos conjuntos de datos se detallan a continuación:\n",
    "\n",
    "* Conjunto de entrenamiento: **6.977 muestras**.\n",
    "* Conjunto de validación: **4.368 muestras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset dimensions: (6977, 7)\n",
      "Test dataset dimensions: (4368, 7)\n"
     ]
    }
   ],
   "source": [
    "# Read EXIST datasets\n",
    "train_df = read_train_dataset()\n",
    "test_df = read_test_dataset()\n",
    "\n",
    "# Show the dimensions of the datasets\n",
    "print(\"Train dataset dimensions:\", train_df.shape)\n",
    "print(\"Test dataset dimensions:\", test_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimentos y modelos\n",
    "\n",
    "Esta sección pretende detallar los experimentos que se realizan a través de la combinación de diferentes técnicas de procesamiento de textos, codificación de documentos y arquitecturas de modelos LSTM. Como se trata de **experimentos no determinísticos**, es decir, los resultados difieren en varias ejecuciones aún con la misma configuración, la estrategia a seguir consiste en realizar **30 iteraciones de cada experimento** para luego calcular la **media de accuracy y AUC**, las métricas de evaluación escogidas para medir la calidad de un clasificador. \n",
    "\n",
    "Por lo tanto las siguientes secciones contienen los detalles del conjunto de experimentos realizados y las conclusiones comparativas alcanzadas, incluyendo el código, la configuración y los resultados únicamente del experimento con mejor rendimiento con respecto a las métricas de evaluación mencionadas.\n",
    "\n",
    "Previo al comienzo de la experimentación se definen tres funciones comunes para el tratamiento y codificación de documentos, carga de embeddings pre-entrenados y validación de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_matrix(\n",
    "    max_n_words: int, sequence_len: int, \n",
    "    lemm: bool = False, stemm: bool = False):\n",
    "    \"\"\"\n",
    "    Process the train and test documents to then convert them\n",
    "    into numeric sequence matrixes so the datasets can be\n",
    "    used to train a LSTM model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_n_words : int\n",
    "        Maximum number of words to keep within the LSTM memory\n",
    "        based on computing the word frequency.\n",
    "    sequence_len : int\n",
    "        Maximum lenght of all sequences.\n",
    "    lemm : bool (optional)\n",
    "        True to apply lemmatization to the train and test documents.\n",
    "    stemm : bool (optional)\n",
    "        True to apply stemming to the train and test documents.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary with the following keys:\n",
    "        - 'tokenizer': a Keras Tokenizer object based on the train documents\n",
    "        that contains the vocabulary to then be used to create the embeddings.\n",
    "        - 'train_matrix', 'test_matrix': the numeric sequence matrixes\n",
    "        after converting the train and test documents.\n",
    "        - 'train_labels', 'test_labels': two numeric lists which contains\n",
    "        the encoded class labels for train and test datasets.\n",
    "    \"\"\"\n",
    "    # Process train and test text documents\n",
    "    processed_df = process_encode_datasets(\n",
    "        train_df=train_df, \n",
    "        test_df=test_df,\n",
    "        lemm=lemm, \n",
    "        stemm=stemm\n",
    "    )\n",
    "\n",
    "    # Processed train texts and encoded train labels \n",
    "    train_texts = list(processed_df[\"train_df\"][\"cleaned_text\"].values)\n",
    "    train_labels = processed_df[\"encoded_train_labels\"]\n",
    "\n",
    "    # Processed test texts and encoded test labels\n",
    "    test_texts = list(processed_df[\"test_df\"][\"cleaned_text\"].values)\n",
    "    test_labels = processed_df[\"encoded_test_labels\"]\n",
    "\n",
    "    # Createa a tokenizer based on train texts\n",
    "    tokenizer = Tokenizer(num_words=max_n_words)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    # Transform each text into a numeric sequence\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    train_matrix = pad_sequences(\n",
    "        sequences=train_sequences, \n",
    "        maxlen=sequence_len)\n",
    "\n",
    "    # Tokenize the test documents using the prior trained tokenizer\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    test_matrix = pad_sequences(\n",
    "        sequences=test_sequences,\n",
    "        maxlen=sequence_len)\n",
    "\n",
    "    return {\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"train_matrix\": train_matrix,\n",
    "        \"train_labels\": train_labels,\n",
    "        \"test_matrix\": test_matrix,\n",
    "        \"test_labels\": test_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(embedding_file: str, tokenizer: Tokenizer, sequence_len: int):\n",
    "    \"\"\"\n",
    "    Load the embeddings stored in the provided file to then\n",
    "    create a matrix with the numeric encoding of each\n",
    "    available word within the tokenizer vocabulary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_file : str\n",
    "        The path to the file which contains a set of embeddings\n",
    "    tokenizer : Tokenizer (Keras)\n",
    "        A trained Keras tokenizer which contains the vocabulary\n",
    "        of the documents to use during the training of models\n",
    "    sequence_len : int\n",
    "        Maximum lenght of all embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A Numpy ndarray which represents an embedding matrix.\n",
    "    \"\"\"\n",
    "    # Load the embeddings stored in a TXT file\n",
    "    embedding_file = open(embedding_file)\n",
    "\n",
    "    # Store each word with its embeddings\n",
    "    embeddings_index = {\n",
    "        line.split()[0]:np.asarray(line.split()[1:], dtype=\"float32\") \n",
    "        for line in embedding_file\n",
    "    }\n",
    "\n",
    "    # Initialize the embedding matrix with zeros\n",
    "    embedding_matrix = np.zeros(shape=(len(tokenizer.word_index)+1, sequence_len))\n",
    "\n",
    "    # Complete the matrix with the prior loaded embeddings\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        # Search for the embeddings of each word\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "\n",
    "        # Words not found will be zeros\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_lstm_model(\n",
    "    model: Model, \n",
    "    train_matrix: np.ndarray, train_labels: list, \n",
    "    test_matrix: np.ndarray, test_labels: list,\n",
    "    metrics_filename: str = None, conf_matrix_filename: str = None):\n",
    "    \"\"\"\n",
    "    Evaluates the provided trained LSTM model over the \n",
    "    train and test datasets to get the accuracy, AUC and\n",
    "    a confusion matrix. To create the predictions for a\n",
    "    binary classification a threshold has been set:\n",
    "        - <= 0.5 represents the negative class (non-sexist).\n",
    "        - > 0.5 represents the positive class (sexist).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Keras model\n",
    "        A trained Keras model to be evaluated.\n",
    "    train_matrix : Numpy ndarray\n",
    "        A numeric sequence matrix with the trained documents.\n",
    "    train_labels : list\n",
    "        A numeric list with the class labels of the train dataset.\n",
    "    test_matrix : Numpy ndarray\n",
    "        A numeric sequence matrix with the test documents.\n",
    "    test_labels : list\n",
    "        A numeric list with the class labels of the test dataset.\n",
    "    metrics_filename : str (optional)\n",
    "        A path and filename to save the metrics over the \n",
    "        train and test datasets in a TXT file.\n",
    "    conf_matrix_filename : str (optional)\n",
    "        A path and filename to save the confusion matrix in\n",
    "        a PNG image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    # Compute and print the accuracy and AUC over train\n",
    "    train_acc = model.evaluate(\n",
    "        x=train_matrix, \n",
    "        y=np.array(train_labels))\n",
    "\n",
    "    print(f\"Accuracy over train dataset: {train_acc[1]}\")\n",
    "    print(f\"AUC over train dataset: {train_acc[2]}\\n\")\n",
    "\n",
    "    # Compute and print the accuracy and AUC over test\n",
    "    test_acc = model.evaluate(\n",
    "        x=test_matrix, \n",
    "        y=np.array(test_labels))\n",
    "\n",
    "    print(f\"Accuracy over test dataset: {test_acc[1]}\")\n",
    "    print(f\"AUC over test dataset: {test_acc[2]}\")\n",
    "\n",
    "    # Generate class label predictions over the test dataset\n",
    "    # Class 0 ~ <= 0.5 | Class 1 ~ > 0.5\n",
    "    test_preds = (model.predict(test_matrix) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Plot the confusion matrix \n",
    "    ConfusionMatrixDisplay(\n",
    "        confusion_matrix=confusion_matrix(\n",
    "            np.array(test_labels), \n",
    "            np.array(test_preds)), \n",
    "        display_labels=[\"Non-sexist\", \"Sexist\"]) \\\n",
    "    .plot()    \n",
    "\n",
    "    # Save the confusion matrix in an image\n",
    "    if (type(conf_matrix_filename) == str and\n",
    "        len(conf_matrix_filename) > 0):\n",
    "        plt.savefig(conf_matrix_filename)\n",
    "\n",
    "    # Save the metrics in a text file\n",
    "    if (type(metrics_filename) == str and\n",
    "        len(metrics_filename) > 0):\n",
    "        opened_file = open(metrics_filename, \"w\")\n",
    "        print(f\"Accuracy over train dataset: {train_acc[1]}\", file=opened_file) \n",
    "        print(f\"AUC over train dataset: {train_acc[2]}\\n\", file=opened_file) \n",
    "        print(f\"Accuracy over test dataset: {test_acc[1]}\", file=opened_file) \n",
    "        print(f\"AUC over test dataset: {test_acc[2]}\", file=opened_file) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Mejor experimento: LSTM básica\n",
    "\n",
    "En esta sección se muestra el código, los resultados y las conclusiones del mejor experimento obtenido con la siguiente **arquitectura LSM básica**.\n",
    "\n",
    "  - 1 capa de entrada: para proporcionar la matriz de datos.\n",
    "  - 1 capa de embeddings: para proporcionar los embeddings pre-entrenados de Glove 6B 50d.\n",
    "  - 1 capa LSTM: con 64 neuronas ocultas para la extracción de características.\n",
    "  - 1 capa de salida: para unificar los datos de la capa anterior en una única salida. \n",
    "  - Función de activación: sigmoidal para calcular la probabilidad de pertenencia de cada muestra.\n",
    "\n",
    "#### Conclusiones\n",
    "\n",
    "* La aplicación de **lematización y/o stemming apenas mejora la capacidad predictiva** del modelo aunque sí aumenta el tiempo de ejecución, especialmente con la primera técnica. Por ello en el mejor experimento únicamente se aplica el siguiente **procesamiento básico**:\n",
    "\n",
    "  - Elimina caracteres especiales, no alfabéticos y signos de puntuación.\n",
    "  - Elimina usuarios mencionados.\n",
    "  - Elimina *stopwords* en inglés y español.\n",
    "  - Elimina palabras sin vocales o compuestas por una única letra.\n",
    "  - <p>Convierte todos los caracteres a minúsculas.</p>\n",
    "\n",
    "* Se ha experimentado con los distintos ficheros de Glove embeddings y si bien se aprecia una **diferencia de más del 2% entre los dos primeros de 50 y 100**, los más pesados aumentan muchísimo el tiempo de ejecución mientras que la mejora con respecto a *accuracy* y AUC no es notable. Por lo tanto se ha optado por utilizar el fichero **glove.6b.100d.txt**.\n",
    "\n",
    "* Adicionalmente se ha experimenado con diversos valores para algunos parámetros como el tamaño del lote (*batch size*), el número de épocas de entrenamiento y criterios de parada temprana (*Early Stopping*). La configuración más propicia para el mejor experimento encontrado para la arquitectura básica mencionada se detalla a continuación:\n",
    "\n",
    "  - **Tamaño del lote: 128**. De entre los distintos experimentos realizados se han probado con valores de 64 y 32. Mientras que con el primero se ha conseguido igualar e incluso mejorar ligeramente las métricas de validación con un *batch size* de 128, el tiempo de ejecución aumenta a más del doble por lo que no parece merecer la pena.\n",
    "\n",
    "  - **Early stopping tras 15 iteraciones sin mejorar el valor de la métrica *AUC* en validación y recuperando los pesos del mejor modelo encontrado**, es decir, con el mínimo valor en esta métrica. Sin la aplicación de esta técnica se ha podido observar el fenómeno de **overfitting** que reduce ligeramente el valor de *accuracy* aunque drásticamente el valor de AUC.\n",
    "\n",
    "  - **Número máximo de iteraciones: 100**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix:\n",
      "[[  0   0   0 ... 211 776  93]\n",
      " [  0   0   0 ... 142 455 856]\n",
      " [  0   0   0 ... 256 257 186]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...  53 327 518]\n",
      " [  0   0   0 ...   2 742   8]]\n",
      "Train labels:[1, 0, 1, 0, 0]\n",
      "\n",
      "Test matrix:\n",
      "[[  0   0   0 ... 259 299  32]\n",
      " [  0   0   0 ... 109   3  48]\n",
      " [  0   0   0 ... 974 180 974]\n",
      " ...\n",
      " [  0   0   0 ... 512 420  97]\n",
      " [  0   0   0 ...   8  37 462]\n",
      " [  0   0   0 ...   5 102 167]]\n",
      "Test labels:[0, 0, 1, 1, 0]\n",
      "\n",
      "Glove 100 d embedding matrix:\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.83380997  0.94426    -0.011362   ... -0.15004     0.83995003\n",
      "   0.48519999]\n",
      " [ 0.52241999 -1.03410006  0.63090003 ... -0.7044      0.16324\n",
      "  -0.23263   ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "MAX_N_WORDS = 1000\n",
    "SEQUENCE_MAX_LEN = 100\n",
    "EMBEDDING_FILE_PATH = \"../embeddings/glove.6B.100d.txt\"\n",
    "APPLY_LEMMATIZATION = False \n",
    "APPLY_STEMMING = False \n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 100\n",
    "VALID_RATE = 0.2\n",
    "MODEL_CALLBACKS = [EarlyStopping(\n",
    "    monitor=\"val_auc\",\n",
    "    min_delta=0.001,\n",
    "    patience=15,\n",
    "    restore_best_weights=True)]\n",
    "LOSS_FUNCTION = \"binary_crossentropy\"\n",
    "OPTIMIZER = \"adam\"\n",
    "VALID_METRICS = [\"accuracy\", \"AUC\"]\n",
    "\n",
    "# Process the train and test documents as well as create\n",
    "# a tokenizer based on the processed train documents\n",
    "processed_data = get_train_test_matrix(\n",
    "    max_n_words=MAX_N_WORDS,\n",
    "    sequence_len=SEQUENCE_MAX_LEN,\n",
    "    lemm=False,\n",
    "    stemm=False\n",
    ")\n",
    "print(f\"Train matrix:\\n{processed_data['train_matrix']}\")\n",
    "print(f\"Train labels:{processed_data['train_labels'][0:5]}\")\n",
    "\n",
    "print(f\"\\nTest matrix:\\n{processed_data['test_matrix']}\")\n",
    "print(f\"Test labels:{processed_data['test_labels'][0:5]}\")\n",
    "\n",
    "# Load the embeddings stored in the defined file path\n",
    "# Encode the train matrix with these embeddings\n",
    "embedding_matrix = get_embedding_matrix(\n",
    "    embedding_file=EMBEDDING_FILE_PATH,\n",
    "    tokenizer=processed_data[\"tokenizer\"],\n",
    "    sequence_len=SEQUENCE_MAX_LEN\n",
    ")\n",
    "print(f\"\\nGlove 100 d embedding matrix:\\n{embedding_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 14:10:51.156234: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 100)          2515000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                42240     \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 65        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,557,305\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 2,515,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 5s 65ms/step - loss: 0.6654 - accuracy: 0.5994 - auc: 0.6124 - val_loss: 0.8142 - val_accuracy: 0.3431 - val_auc: 0.5223\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.6284 - accuracy: 0.6479 - auc: 0.6944 - val_loss: 0.7791 - val_accuracy: 0.4148 - val_auc: 0.5528\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.6082 - accuracy: 0.6669 - auc: 0.7240 - val_loss: 0.8398 - val_accuracy: 0.3918 - val_auc: 0.5580\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 57ms/step - loss: 0.5969 - accuracy: 0.6816 - auc: 0.7392 - val_loss: 0.8723 - val_accuracy: 0.4011 - val_auc: 0.5657\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.5795 - accuracy: 0.6956 - auc: 0.7598 - val_loss: 0.9148 - val_accuracy: 0.4140 - val_auc: 0.5717\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.5649 - accuracy: 0.7110 - auc: 0.7759 - val_loss: 0.8005 - val_accuracy: 0.5000 - val_auc: 0.5859\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.5567 - accuracy: 0.7155 - auc: 0.7826 - val_loss: 0.8082 - val_accuracy: 0.5036 - val_auc: 0.5914\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.5379 - accuracy: 0.7362 - auc: 0.8022 - val_loss: 0.9591 - val_accuracy: 0.4441 - val_auc: 0.5876\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.5252 - accuracy: 0.7391 - auc: 0.8126 - val_loss: 0.8112 - val_accuracy: 0.4986 - val_auc: 0.5984\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.5146 - accuracy: 0.7483 - auc: 0.8213 - val_loss: 0.8932 - val_accuracy: 0.4943 - val_auc: 0.5955\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.4997 - accuracy: 0.7581 - auc: 0.8340 - val_loss: 0.8712 - val_accuracy: 0.5036 - val_auc: 0.6039\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.4831 - accuracy: 0.7724 - auc: 0.8461 - val_loss: 1.0284 - val_accuracy: 0.4606 - val_auc: 0.5908\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.4698 - accuracy: 0.7791 - auc: 0.8563 - val_loss: 0.9159 - val_accuracy: 0.5150 - val_auc: 0.6015\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.4609 - accuracy: 0.7843 - auc: 0.8611 - val_loss: 1.0106 - val_accuracy: 0.4807 - val_auc: 0.5962\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.4389 - accuracy: 0.7959 - auc: 0.8768 - val_loss: 0.8580 - val_accuracy: 0.5272 - val_auc: 0.6046\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.4256 - accuracy: 0.8045 - auc: 0.8846 - val_loss: 0.9164 - val_accuracy: 0.5150 - val_auc: 0.5960\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.4108 - accuracy: 0.8183 - auc: 0.8936 - val_loss: 0.8076 - val_accuracy: 0.5652 - val_auc: 0.6025\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.3910 - accuracy: 0.8235 - auc: 0.9052 - val_loss: 1.1099 - val_accuracy: 0.4936 - val_auc: 0.5893\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.3730 - accuracy: 0.8316 - auc: 0.9141 - val_loss: 0.9697 - val_accuracy: 0.5365 - val_auc: 0.5980\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.3565 - accuracy: 0.8429 - auc: 0.9229 - val_loss: 1.0376 - val_accuracy: 0.5423 - val_auc: 0.5975\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.3412 - accuracy: 0.8486 - auc: 0.9288 - val_loss: 0.9239 - val_accuracy: 0.5702 - val_auc: 0.5951\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.3252 - accuracy: 0.8586 - auc: 0.9366 - val_loss: 1.1397 - val_accuracy: 0.5201 - val_auc: 0.5967\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.3116 - accuracy: 0.8653 - auc: 0.9422 - val_loss: 1.1330 - val_accuracy: 0.5387 - val_auc: 0.5930\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.2901 - accuracy: 0.8746 - auc: 0.9500 - val_loss: 1.1759 - val_accuracy: 0.5394 - val_auc: 0.6003\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.2816 - accuracy: 0.8803 - auc: 0.9539 - val_loss: 1.1825 - val_accuracy: 0.5458 - val_auc: 0.5907\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.2657 - accuracy: 0.8862 - auc: 0.9590 - val_loss: 1.2614 - val_accuracy: 0.5358 - val_auc: 0.5922\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.2559 - accuracy: 0.8889 - auc: 0.9621 - val_loss: 1.2118 - val_accuracy: 0.5394 - val_auc: 0.5957\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.2371 - accuracy: 0.9045 - auc: 0.9692 - val_loss: 1.4461 - val_accuracy: 0.5179 - val_auc: 0.5956\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.2261 - accuracy: 0.9070 - auc: 0.9719 - val_loss: 1.3259 - val_accuracy: 0.5466 - val_auc: 0.5911\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.2119 - accuracy: 0.9140 - auc: 0.9757 - val_loss: 1.4998 - val_accuracy: 0.5244 - val_auc: 0.5939\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.2108 - accuracy: 0.9152 - auc: 0.9749 - val_loss: 1.6039 - val_accuracy: 0.5236 - val_auc: 0.5957\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.1923 - accuracy: 0.9253 - auc: 0.9805 - val_loss: 1.5655 - val_accuracy: 0.5401 - val_auc: 0.5953\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.1894 - accuracy: 0.9235 - auc: 0.9804 - val_loss: 1.5523 - val_accuracy: 0.5415 - val_auc: 0.5939\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.1862 - accuracy: 0.9262 - auc: 0.9809 - val_loss: 1.3559 - val_accuracy: 0.5595 - val_auc: 0.5885\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.1731 - accuracy: 0.9324 - auc: 0.9840 - val_loss: 1.4186 - val_accuracy: 0.5580 - val_auc: 0.6010\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.1673 - accuracy: 0.9328 - auc: 0.9850 - val_loss: 1.7832 - val_accuracy: 0.5222 - val_auc: 0.5959\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1610 - accuracy: 0.9353 - auc: 0.9861 - val_loss: 1.6378 - val_accuracy: 0.5609 - val_auc: 0.6028\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1651 - accuracy: 0.9339 - auc: 0.9853 - val_loss: 1.8001 - val_accuracy: 0.5301 - val_auc: 0.5924\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1475 - accuracy: 0.9439 - auc: 0.9888 - val_loss: 1.8568 - val_accuracy: 0.5365 - val_auc: 0.5967\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1464 - accuracy: 0.9419 - auc: 0.9885 - val_loss: 1.8752 - val_accuracy: 0.5365 - val_auc: 0.5973\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1455 - accuracy: 0.9448 - auc: 0.9890 - val_loss: 2.2429 - val_accuracy: 0.5072 - val_auc: 0.5877\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.1466 - accuracy: 0.9416 - auc: 0.9885 - val_loss: 1.8249 - val_accuracy: 0.5466 - val_auc: 0.5973\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1619 - accuracy: 0.9362 - auc: 0.9852 - val_loss: 2.0609 - val_accuracy: 0.5301 - val_auc: 0.6005\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1351 - accuracy: 0.9505 - auc: 0.9906 - val_loss: 2.0067 - val_accuracy: 0.5251 - val_auc: 0.5942\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1249 - accuracy: 0.9522 - auc: 0.9921 - val_loss: 2.2003 - val_accuracy: 0.5079 - val_auc: 0.5876\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1206 - accuracy: 0.9538 - auc: 0.9928 - val_loss: 2.1369 - val_accuracy: 0.5344 - val_auc: 0.5975\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1155 - accuracy: 0.9548 - auc: 0.9932 - val_loss: 2.3069 - val_accuracy: 0.5251 - val_auc: 0.5925\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1113 - accuracy: 0.9568 - auc: 0.9937 - val_loss: 2.3197 - val_accuracy: 0.5265 - val_auc: 0.5916\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1106 - accuracy: 0.9565 - auc: 0.9936 - val_loss: 2.3369 - val_accuracy: 0.5236 - val_auc: 0.5886\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.1071 - accuracy: 0.9597 - auc: 0.9943 - val_loss: 2.6535 - val_accuracy: 0.5043 - val_auc: 0.5803\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1226 - accuracy: 0.9520 - auc: 0.9919 - val_loss: 2.3307 - val_accuracy: 0.5193 - val_auc: 0.5905\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.1238 - accuracy: 0.9513 - auc: 0.9919 - val_loss: 2.3067 - val_accuracy: 0.5251 - val_auc: 0.5787\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1323 - accuracy: 0.9493 - auc: 0.9901 - val_loss: 2.2896 - val_accuracy: 0.5122 - val_auc: 0.5893\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.1400 - accuracy: 0.9443 - auc: 0.9884 - val_loss: 1.7983 - val_accuracy: 0.5530 - val_auc: 0.5756\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.1354 - accuracy: 0.9486 - auc: 0.9898 - val_loss: 1.9825 - val_accuracy: 0.5466 - val_auc: 0.5868\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.1027 - accuracy: 0.9609 - auc: 0.9949 - val_loss: 2.1243 - val_accuracy: 0.5430 - val_auc: 0.5834\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0960 - accuracy: 0.9651 - auc: 0.9953 - val_loss: 2.2897 - val_accuracy: 0.5279 - val_auc: 0.5850\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0919 - accuracy: 0.9645 - auc: 0.9959 - val_loss: 2.4228 - val_accuracy: 0.5258 - val_auc: 0.5870\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.0907 - accuracy: 0.9651 - auc: 0.9959 - val_loss: 2.1408 - val_accuracy: 0.5544 - val_auc: 0.5913\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.0901 - accuracy: 0.9640 - auc: 0.9960 - val_loss: 2.5117 - val_accuracy: 0.5251 - val_auc: 0.5857\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0868 - accuracy: 0.9667 - auc: 0.9962 - val_loss: 2.3254 - val_accuracy: 0.5437 - val_auc: 0.5914\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0850 - accuracy: 0.9669 - auc: 0.9963 - val_loss: 2.6015 - val_accuracy: 0.5229 - val_auc: 0.5849\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0837 - accuracy: 0.9663 - auc: 0.9965 - val_loss: 2.5072 - val_accuracy: 0.5365 - val_auc: 0.5879\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0827 - accuracy: 0.9681 - auc: 0.9965 - val_loss: 2.6444 - val_accuracy: 0.5272 - val_auc: 0.5865\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.0801 - accuracy: 0.9683 - auc: 0.9967 - val_loss: 2.3974 - val_accuracy: 0.5580 - val_auc: 0.5899\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.0795 - accuracy: 0.9694 - auc: 0.9967 - val_loss: 2.7355 - val_accuracy: 0.5308 - val_auc: 0.5842\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.0784 - accuracy: 0.9679 - auc: 0.9969 - val_loss: 2.9834 - val_accuracy: 0.5201 - val_auc: 0.5823\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0779 - accuracy: 0.9690 - auc: 0.9969 - val_loss: 2.8213 - val_accuracy: 0.5258 - val_auc: 0.5839\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.0764 - accuracy: 0.9692 - auc: 0.9969 - val_loss: 2.7436 - val_accuracy: 0.5344 - val_auc: 0.5837\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0747 - accuracy: 0.9704 - auc: 0.9971 - val_loss: 2.9510 - val_accuracy: 0.5215 - val_auc: 0.5823\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.0755 - accuracy: 0.9679 - auc: 0.9970 - val_loss: 2.9890 - val_accuracy: 0.5251 - val_auc: 0.5864\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0734 - accuracy: 0.9701 - auc: 0.9970 - val_loss: 3.0009 - val_accuracy: 0.5294 - val_auc: 0.5805\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.0729 - accuracy: 0.9695 - auc: 0.9970 - val_loss: 2.8073 - val_accuracy: 0.5408 - val_auc: 0.5861\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.0715 - accuracy: 0.9704 - auc: 0.9971 - val_loss: 2.9256 - val_accuracy: 0.5344 - val_auc: 0.5862\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.0703 - accuracy: 0.9703 - auc: 0.9974 - val_loss: 2.8135 - val_accuracy: 0.5415 - val_auc: 0.5863\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0698 - accuracy: 0.9703 - auc: 0.9972 - val_loss: 3.0305 - val_accuracy: 0.5294 - val_auc: 0.5839\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0690 - accuracy: 0.9708 - auc: 0.9972 - val_loss: 3.0048 - val_accuracy: 0.5330 - val_auc: 0.5822\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0758 - accuracy: 0.9683 - auc: 0.9964 - val_loss: 3.0255 - val_accuracy: 0.5244 - val_auc: 0.5886\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1139 - accuracy: 0.9563 - auc: 0.9913 - val_loss: 2.4064 - val_accuracy: 0.5301 - val_auc: 0.5925\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1925 - accuracy: 0.9335 - auc: 0.9773 - val_loss: 2.4655 - val_accuracy: 0.5358 - val_auc: 0.6019\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.1613 - accuracy: 0.9396 - auc: 0.9831 - val_loss: 2.1070 - val_accuracy: 0.5587 - val_auc: 0.5999\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.0911 - accuracy: 0.9654 - auc: 0.9957 - val_loss: 2.2971 - val_accuracy: 0.5380 - val_auc: 0.5957\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0741 - accuracy: 0.9712 - auc: 0.9973 - val_loss: 2.4839 - val_accuracy: 0.5372 - val_auc: 0.5927\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.0701 - accuracy: 0.9710 - auc: 0.9975 - val_loss: 2.6424 - val_accuracy: 0.5358 - val_auc: 0.5940\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.0680 - accuracy: 0.9708 - auc: 0.9974 - val_loss: 2.6560 - val_accuracy: 0.5358 - val_auc: 0.5936\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0668 - accuracy: 0.9720 - auc: 0.9975 - val_loss: 2.7273 - val_accuracy: 0.5308 - val_auc: 0.5928\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.0664 - accuracy: 0.9719 - auc: 0.9975 - val_loss: 2.8982 - val_accuracy: 0.5215 - val_auc: 0.5917\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.0649 - accuracy: 0.9719 - auc: 0.9975 - val_loss: 2.9133 - val_accuracy: 0.5208 - val_auc: 0.5897\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0647 - accuracy: 0.9719 - auc: 0.9975 - val_loss: 2.9137 - val_accuracy: 0.5236 - val_auc: 0.5926\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.0640 - accuracy: 0.9724 - auc: 0.9977 - val_loss: 2.8241 - val_accuracy: 0.5301 - val_auc: 0.5914\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.0634 - accuracy: 0.9715 - auc: 0.9976 - val_loss: 3.0080 - val_accuracy: 0.5244 - val_auc: 0.5899\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.0627 - accuracy: 0.9719 - auc: 0.9976 - val_loss: 2.8701 - val_accuracy: 0.5337 - val_auc: 0.5908\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.0623 - accuracy: 0.9722 - auc: 0.9977 - val_loss: 3.2856 - val_accuracy: 0.5129 - val_auc: 0.5863\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.0621 - accuracy: 0.9717 - auc: 0.9977 - val_loss: 3.4871 - val_accuracy: 0.5043 - val_auc: 0.5840\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.0611 - accuracy: 0.9728 - auc: 0.9976 - val_loss: 3.0049 - val_accuracy: 0.5294 - val_auc: 0.5898\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.0601 - accuracy: 0.9726 - auc: 0.9978 - val_loss: 3.0878 - val_accuracy: 0.5279 - val_auc: 0.5930\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.0597 - accuracy: 0.9724 - auc: 0.9978 - val_loss: 3.0853 - val_accuracy: 0.5279 - val_auc: 0.5905\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.0603 - accuracy: 0.9715 - auc: 0.9977 - val_loss: 3.3534 - val_accuracy: 0.5201 - val_auc: 0.5894\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.0593 - accuracy: 0.9729 - auc: 0.9978 - val_loss: 3.2348 - val_accuracy: 0.5244 - val_auc: 0.5905\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.0584 - accuracy: 0.9724 - auc: 0.9979 - val_loss: 2.9131 - val_accuracy: 0.5430 - val_auc: 0.5874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc3d71a1c60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM ARCHITECTURE\n",
    "## Input layer\n",
    "input_layer = Input(\n",
    "    name=\"inputs\",\n",
    "    shape=[SEQUENCE_MAX_LEN])\n",
    "\n",
    "## Embedding layer: pre-trained embeddings\n",
    "layer = Embedding(\n",
    "    input_dim=len(processed_data[\"tokenizer\"].word_index)+1,\n",
    "    output_dim=SEQUENCE_MAX_LEN,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=MAX_N_WORDS,\n",
    "    trainable=False)(input_layer)\n",
    "\n",
    "## LSTM layer\n",
    "layer = LSTM(units=64)(layer)\n",
    "\n",
    "## Output layer\n",
    "layer = Dense(\n",
    "    name=\"output\",\n",
    "    units=1)(layer)\n",
    "\n",
    "## Activation layer\n",
    "output_layer = Activation(activation=\"sigmoid\")(layer)\n",
    "\n",
    "# CREATE A LSTM MODEL WITH THE PRIOR ARCHITECTURE\n",
    "## Model object\n",
    "lstm_model1 = Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=output_layer)\n",
    "\n",
    "## Summary of the model\n",
    "lstm_model1.summary()\n",
    "\n",
    "## Compile the model \n",
    "lstm_model1.compile(\n",
    "    loss=LOSS_FUNCTION,\n",
    "    optimizer=OPTIMIZER,\n",
    "    metrics=VALID_METRICS)\n",
    "\n",
    "# LSTM TRAINING\n",
    "## Train the prior built model\n",
    "lstm_model1.fit(\n",
    "    x=processed_data[\"train_matrix\"], \n",
    "    y=np.array(processed_data[\"train_labels\"]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=N_EPOCHS,\n",
    "    validation_split=VALID_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal y como se puede apreciar en los siguientes resultados, la tasa de aciertos sobre el conjunto de entrenamiento es bastante alta con un 88% aunque sobre el conjunto de **test apenas alcanza el 61% de accuracy**. Considerando el valor desmesurádamente bajo del área bajo la curva ROC en base al mismo conjunto de datos se puede concluir que la **capacidad de predicción del modelo apenas supera la de un clasificador aleatorio**. \n",
    "\n",
    "Observando la matriz de confusión es altamente notable la **elevada tasa de falsos negativos**, es decir, textos sexistas que no han sido detectados. Por lo tanto con una arquitectura LSTM básica y la mejor configuración encontrada en este grupo de experimentos, parece no ser suficiente precisa como para construir un clasificador de calidad capaz de identificar textos sexistas y no sexistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6286 - accuracy: 0.8876 - auc: 0.9282\n",
      "Accuracy over train dataset: 0.8876307606697083\n",
      "AUC over train dataset: 0.9282481074333191\n",
      "\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 2.3191 - accuracy: 0.6074 - auc: 0.6478\n",
      "Accuracy over test dataset: 0.6073718070983887\n",
      "AUC over test dataset: 0.647753119468689\n",
      "137/137 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## LSTM VALIDATION\n",
    "## Evaluate the trained LSTM model over train and test datasets\n",
    "validate_lstm_model(\n",
    "    model=lstm_model1,\n",
    "    train_matrix=processed_data[\"train_matrix\"],\n",
    "    train_labels=processed_data[\"train_labels\"],\n",
    "    test_matrix=processed_data[\"test_matrix\"],\n",
    "    test_labels=processed_data[\"test_labels\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00f7dc61815a6da5453fee0a1d7c3baaa88d552412e55cf65ecdf10d17265d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

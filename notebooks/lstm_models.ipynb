{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos LSTM\n",
    "\n",
    "## 1. Introducción a LSTM\n",
    "\n",
    "LSTM es un acrónimo de *Long-Short Term Memory* y representa a un **subtipo de RNN** (*Recurrent Neural Network*) capaz de **retener información relevante** sobre datos ya procesados que ayude al procesamiento de nuevas secuencias de datos completas. Su arquitectura se encuentra compuesta a su vez por tres redes neuronales:\n",
    "\n",
    "* ***Forget Gate***: este primer modelo es el encargado de filtrar qué información previa es útil para su almacenamiento y qué datos ya no son útiles para futuras iteraciones. \n",
    "\n",
    "* ***Input Gate***: esta segunda red trata de determinar el valor que presentan los datos entrantes para resolver la tarea de clasificación.\n",
    "\n",
    "* ***Output Gate***: finalmente esta red calcula las salidas del modelo LSTM que dependerán de la tarea de clasificación que se pretende abordar.\n",
    "\n",
    "### 1.1. Introducción a BiLSTM\n",
    "\n",
    "Se trata de una variante de la arquitectura compuesta por **dos redes LSTM independientes** con el objetivo de procesar los textos de derecha a izquierda y viceversa. Esta característica permite la **extracción de características en ambos sentidos** proporcionando un **contexto más voluminoso y preciso** al considerar los **términos precedores y sucesores**, almacenando así información pasada y futura del texto. Así, generalmente las redes BiLSTM tienden a mejorar el rendimiento y su capacidad preditiva.\n",
    "\n",
    "### 1.2. Condiciones de uso\n",
    "\n",
    "Dependiendo del framework que se pretenda utilizar (Tensorflow, Keras, Pytorch) existen diferentes tratamientos de datos y requisitos de implementación que se deben cumplir al definir la arquitectura, entrenamiento y validación de modelos. En mi caso particular he optado por utilizar **Keras** debido a la experiencia previa que tengo con la librería y a su facilidad de uso. \n",
    "\n",
    "1. **Procesamiento y limpieza** de los documentos.\n",
    "\n",
    "2. **Tokenización** de los documentos especificando un token para aquellos términos que no sean reconocidos dentro de un vocabulario de palabras.\n",
    "\n",
    "3. **Codificación** numérica en forma de matrices secuenciales de valores. \n",
    "\n",
    "5. **Normalización** de las secuencias numéricas para establecer un mismo **tamaño fijo**, completando con ceros aquellas de menor longitud y separando en varias secuencias aquellas que dispongan de un mayor tamaño.\n",
    "\n",
    "6. Definición de la arquitectura de un **modelo** e instanciación para su posterior entrenamiento y validación.\n",
    "\n",
    "### 1.3. Casos de uso\n",
    "\n",
    "* Detección y extracción de patrones en secuencias de datos.\n",
    "* Modelado del lenguaje natural.\n",
    "* Traducción de texto.\n",
    "* Reconocimiento de textos manuscritos.\n",
    "* Generación de imágenes mediante mecanismos de atención.\n",
    "* Sistemas de preguntas y respuestas.\n",
    "* Conversión de vídeo a texto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estructura del notebook\n",
    "\n",
    "1. Introducción a LSTM\n",
    "2. Estructura del notebook\n",
    "3. Instalación y carga de librerías\n",
    "4. Lectura y carga de datos\n",
    "5. Experimentos y modelos\n",
    "6. Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instalación y carga de librerías\n",
    "\n",
    "Este apartado tiene como único propósito cargar las librerías y dependencias necesarias para la ejecución de este notebook, así como las funciones propiamente desarrolladas. Previo a ello deberán ser instaladas bien ejecutando el script *setup.sh* mediante el comando `bash setup.sh` con permisos de ejecución en distribuciones Linux, o bien ejecutando el compando `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# pandas: to read the datasets\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: to work with Numpy ndarrays\n",
    "import numpy as np\n",
    "\n",
    "# keras: to load pre-trained models\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# sklearn: to plot a confusion matrix per trained model\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# matplotlib: to plot charts\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# data: to analyze test predictions\n",
    "from data import analyze_predicted_probs, map_texts_to_emotions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lectura y carga de datos procesados\n",
    "\n",
    "En esta sección se pretende leer y cargar los datos de entrenamiento y test ya procesados a los que se les ha aplicado las siguientes técnicas de tratamiento de documentos:\n",
    "\n",
    "  - Elimina URLs.\n",
    "  - Elimina usuarios mencionados.\n",
    "  - Elimina caracteres especiales, no alfabéticos y signos de puntuación.\n",
    "  - Convierte todos los caracteres en minúsculas.\n",
    "  - **No se aplica lematización** puesto que el rendimiento del modelo apenas mejora aunque el tiempo invertido se multiplica exponencialmente.\n",
    "  - **No se intenta detectar y corregir palabras erróneamente escritas** puesto que tampoco mejora el rendimiento del modelo pero la inversión de recursos es desorbitada. Según he podido comprobar apenas se detecta un 9,43% de términos con faltas de ortogragía y solo un 7,61% son corregidos, por lo que esta técnica no parece que vaya a ser de utilidad. </p>\n",
    "\n",
    "Tal y como se puede comprobar en los siguientes resultados las dimensiones de sendos conjuntos de datos se detallan a continuación:\n",
    "\n",
    "* Conjunto de entrenamiento: **6.865 muestras**.\n",
    "* Conjunto de validación: **4.296 muestras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset dimensions: (6865, 6)\n",
      "Test dataset dimensions: (4296, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read already processed EXIST datasets\n",
    "train_df = pd.read_csv('../data/proc_EXIST2021_train.csv')\n",
    "test_df = pd.read_csv('../data/proc_EXIST2021_test.csv')\n",
    "\n",
    "# Show the dimensions of the datasets\n",
    "print('Train dataset dimensions:', train_df.shape)\n",
    "print('Test dataset dimensions:', test_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimentos y modelos\n",
    "\n",
    "En esta sección se pretende ejemplificar la mejor configuración obtenida en relación a la combinación de distintas técnicas de procesamiento de textos, codificación de documentos y arquitecturas LSTM/BiLSTM, como modelos de Aprendizaje Automático avanzados. A diferencia de los clasificadores entrenados con Regresión Logística, los experimentos efectuados con LSTM/BiLSTM **no son determinísticos**. Como consecuencia, para evaluar el impacto de las modificaciones realizadas sobre los datasets y las arquitecturas se ejecutan **30 iteraciones de cada experimento** para luego calcular la **media de accuracy y AUC**, como métricas de evaluación seleccionadas para medir la calidad de un clasificador. Para más detalles se puede consultar [este notebook](https://github.com/lidiasm/DATCOM-TFM/blob/main/notebooks/run_lstm_experiments.ipynb) donde se encuentra codificado el procedimiento descrito.\n",
    "\n",
    "Tal y como se explica en ambas competiciones, se realiza una **distinción entre textos en inglés y español** puesto que parece ser que estos últimos se caracterizan por una mejor representación y por ende, los **clasificadores entrenados únicamente sobre documentos españoles demuestran una mayor capacidad de predicción**.\n",
    "\n",
    "Previo al comienzo de la experimentación se definen las siguientes tres funciones con las que transformar los conjuntos de datos ya procesados en matrices numéricas con las que generar la matriz de embeddings y evaluar los modelos ya entrenados sobre sendos datasets con el objetivo de posteriormente analizar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data_as_matrixes(train_texts:list, test_texts: list, max_n_words: int, sequence_len: int):\n",
    "    '''\n",
    "    Function that creates and trains a Keras tokenizer based on the provided\n",
    "    train documents to encode the train and test data as numeric matrixes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_texts : list\n",
    "        A list of strings with the train documents to encode.\n",
    "    test_texts : list\n",
    "        A list of strings with the test documents to encode.\n",
    "    max_n_words : int\n",
    "        Maximum number of words to keep within the LSTM memory\n",
    "        based on computing the word frequency.\n",
    "    sequence_len : int\n",
    "        Maximum lenght of all sequences.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "    '''\n",
    "    # Create a tokenizer based on train texts\n",
    "    tokenizer = Tokenizer(num_words=max_n_words)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    # Transform each text into a numeric sequence\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    train_matrix = pad_sequences(\n",
    "        sequences=train_sequences, \n",
    "        maxlen=sequence_len)\n",
    "\n",
    "    # Tokenize the test documents using the prior trained tokenizer\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    test_matrix = pad_sequences(\n",
    "        sequences=test_sequences,\n",
    "        maxlen=sequence_len)\n",
    "    \n",
    "    return tokenizer, train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(embedding_file: str, tokenizer: Tokenizer, sequence_len: int):\n",
    "    '''\n",
    "    Load the embeddings stored in the provided file to then\n",
    "    create a matrix with the numeric encoding of each\n",
    "    available word within the tokenizer vocabulary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_file : str\n",
    "        The path to the file which contains a set of embeddings\n",
    "    tokenizer : Tokenizer (Keras)\n",
    "        A trained Keras tokenizer which contains the vocabulary\n",
    "        of the documents to use during the training of models\n",
    "    sequence_len : int\n",
    "        Maximum lenght of all embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A Numpy ndarray which represents an embedding matrix.\n",
    "    '''\n",
    "    # Load the embeddings stored in a TXT file\n",
    "    embedding_file = open(embedding_file)\n",
    "\n",
    "    # Store each word with its embeddings\n",
    "    embeddings_index = {\n",
    "        line.split()[0]:np.asarray(line.split()[1:], dtype='float32') \n",
    "        for line in embedding_file\n",
    "    }\n",
    "\n",
    "    # Initialize the embedding matrix with zeros\n",
    "    embedding_matrix = np.zeros(shape=(len(tokenizer.word_index)+1, sequence_len))\n",
    "\n",
    "    # Complete the matrix with the prior loaded embeddings\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        # Search for the embeddings of each word\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "\n",
    "        # Words not found will be zeros\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_lstm_model(\n",
    "    model: Model, \n",
    "    train_matrix: np.ndarray, train_labels: list, \n",
    "    test_matrix: np.ndarray, test_labels: list):\n",
    "    '''\n",
    "    Evaluates the provided trained LSTM model over the \n",
    "    train and test datasets to get the accuracy, AUC and\n",
    "    a confusion matrix. To create the predictions for a\n",
    "    binary classification a threshold has been set:\n",
    "        - <= 0.5 represents the negative class (non-sexist).\n",
    "        - > 0.5 represents the positive class (sexist).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Keras model\n",
    "        A trained Keras model to be evaluated.\n",
    "    train_matrix : Numpy ndarray\n",
    "        A numeric sequence matrix with the trained documents.\n",
    "    train_labels : list\n",
    "        A numeric list with the class labels of the train dataset.\n",
    "    test_matrix : Numpy ndarray\n",
    "        A numeric sequence matrix with the test documents.\n",
    "    test_labels : list\n",
    "        A numeric list with the class labels of the test dataset.\n",
    "    '''\n",
    "    # Compute and print the accuracy and AUC over train\n",
    "    train_acc = model.evaluate(\n",
    "        x=train_matrix, \n",
    "        y=np.array(train_labels))\n",
    "\n",
    "    print(f'Train accuracy: {train_acc[1]}')\n",
    "    print(f'Train AUC: {train_acc[2]}\\n')\n",
    "\n",
    "    # Compute and print the accuracy and AUC over test\n",
    "    test_acc = model.evaluate(\n",
    "        x=test_matrix, \n",
    "        y=np.array(test_labels))\n",
    "\n",
    "    print(f'Test accuracy: {test_acc[1]}')\n",
    "    print(f'Test AUC: {test_acc[2]}')\n",
    "\n",
    "    # Generate class label predictions over the test dataset\n",
    "    test_preds = (model.predict(test_matrix) >= 0.5).astype('int32')\n",
    "\n",
    "    # Plot the confusion matrix \n",
    "    ConfusionMatrixDisplay(\n",
    "        confusion_matrix=confusion_matrix(\n",
    "            np.array(test_labels), \n",
    "            np.array(test_preds)), \n",
    "        display_labels=['Non-sexist', 'Sexist']) \\\n",
    "    .plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Modelo específico para inglés\n",
    "\n",
    "* **Codificación de textos mediante embeddings**. Tras experimentar con diferentes ficheros situados en el siguiente [enlace](https://nlp.stanford.edu/projects/glove/), por ser **multilenguaje**, estar basado en un **mayor número de vocabulario** y por proporcionar un buen balance entre el rendimiento de los modelos y la inversión de recursos necesarios, he seleccionado el archivo **glove.twitter.27B.100d.txt**.\n",
    "\n",
    "* **Arquitectura e hiperparámetros**.\n",
    "  * 1 capa de entrada para proporcionar los documentos procesados.\n",
    "  * **2 capas ocultas con 128 neuronas** cada una.\n",
    "  * 1 capa de salida con la que asignar una clase a cada muestra.\n",
    "  * **Tamaño del lote: 32**.\n",
    "  * <p>Máximo número de palabras que se mantienen en memoria: 1.000.</p>\n",
    "\n",
    "* **Entrenamiento y validación**.\n",
    "  * Número máximo de **iteraciones**: 100.\n",
    "  * **Early Stopping** tras 15 iteraciones sin una mejora mayor que 0.01 en el valor de la métrica *AUC* en validación y recuperando los pesos del mejor modelo encontrado. \n",
    "  * Porcentaje de **validación**: 20%.\n",
    "  * Función de pérdida: *binary_crossentropy*.\n",
    "  * Optimizador: Adam.\n",
    "  * **Métricas de validación**: *accuracy* y AUC.\n",
    "\n",
    "Tal y como se puede apreciar en los siguientes resultados, la tasa de aciertos sobre el conjunto de entrenamiento apenas alcanza un 78% mientras que sobre **test únicamente existe un 70% de accuracy**. Parece que esta diferencia no es demasiado notable como para detectar cierto *overfitting* y observando el área bajo la curva ROC del conjunto de test se puede determinar que el modelo **no dispone de una buena capacidad de predicción**. \n",
    "\n",
    "Observando la matriz de confusión es altamente notable la **elevada tasa de falsos negativos**, es decir, textos sexistas que no han sido detectados. Por lo tanto una arquitectura LSTM y la mejor configuración encontrada en este grupo de experimentos, parece no ser suficiente precisa como para construir un clasificador de calidad capaz de identificar textos sexistas y no sexistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 7s 60ms/step - loss: 0.4713 - accuracy: 0.7778 - auc: 0.8626\n",
      "Train accuracy: 0.7777777910232544\n",
      "Train AUC: 0.8626314997673035\n",
      "\n",
      "69/69 [==============================] - 4s 59ms/step - loss: 0.6212 - accuracy: 0.7042 - auc: 0.7715\n",
      "Test accuracy: 0.7041800618171692\n",
      "Test AUC: 0.771522581577301\n",
      "69/69 [==============================] - 10s 116ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of words to retain in the LSTM memory\n",
    "MAX_N_WORDS = 1000\n",
    "\n",
    "# Max number of tokens per numeric sequence\n",
    "SEQUENCE_MAX_LEN = 100\n",
    "\n",
    "# Path to the multilanguage embedding file\n",
    "MULTILAN_EMBEDDINGS_FILE = '../en_es_embeddings/glove.twitter.27B.100d.txt'\n",
    "\n",
    "# Filter train and test texts by language\n",
    "en_train_df = train_df[train_df['language'] == 'en']\n",
    "en_test_df = test_df[test_df['language'] == 'en']\n",
    "\n",
    "# Convert processed train and test documents into matrixes\n",
    "en_tokenizer, en_train_matrix, en_test_matrix = encode_data_as_matrixes(\n",
    "    train_texts=list(en_train_df['clean_text'].values),\n",
    "    test_texts=list(en_test_df['clean_text'].values),\n",
    "    max_n_words=MAX_N_WORDS,\n",
    "    sequence_len=SEQUENCE_MAX_LEN\n",
    ")\n",
    "\n",
    "# Get the embedding matrix based on the train documents\n",
    "en_embed_matrix = get_embedding_matrix(\n",
    "    embedding_file=MULTILAN_EMBEDDINGS_FILE,\n",
    "    tokenizer=en_tokenizer,\n",
    "    sequence_len=SEQUENCE_MAX_LEN\n",
    ")\n",
    "\n",
    "# Load a pretrained BiLSTM model trained over English texts\n",
    "en_bilstm_model = load_model('../models/en_lstm_models/en_bilstm_model_2L_128N_32BS.h5')\n",
    "\n",
    "# Evaluate the model over train and test datasets\n",
    "validate_lstm_model(\n",
    "    model=en_bilstm_model,\n",
    "    train_matrix=en_train_matrix,\n",
    "    train_labels=list(en_train_df['task1'].values),\n",
    "    test_matrix=en_test_matrix,\n",
    "    test_labels=list(en_test_df['task1'].values)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1. Análisis de resultados\n",
    "\n",
    "Con el propósito de tratar de identificar la existencia de posibles patrones que dificultan la construcción de un clasificador de calidad para detectar textos sexistas y no sexistas, se ha realizado la siguiente experimentación. Consiste en evaluar las **muestras mal clasificadas** de cada categoría a partir de intervalos de confianza para posteriormente cruzar los ejemplos resultantes con el **análisis de emociones y las categorías sexistas** de la columna *task2*, para las muestras de la clase positiva. \n",
    "\n",
    "En los siguientes resultados podemos observar cómo la **gran mayoría de falsos negativos han sido clasificados en base a umbrales ínfimos de confianza**, por lo que el modelo no parece estar nada seguro acerca de las decisiones que ha tomado. Esta situación puede ser más beneficiosa puesto que se pueden aplicar técnicas a priori o a posteriori para ayudar a mejorar la clasificación. Sin embargo, el fenómeno contrario ocurre con los **falsos positivos, puesto que la mayoría de estos casos se concentran en los intervalos de confianza más altos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 4s 53ms/step\n",
      "69/69 [==============================] - 4s 64ms/step\n",
      "FALSE NEGATIVES\n",
      "Confidence Interval Very low (0.0, 0.2): 182 samples\n",
      "Confidence Interval Low (0.2, 0.4): 123 samples\n",
      "Confidence Interval Medium (0.4, 0.6): 93 samples\n",
      "Confidence Interval High (0.6, 0.8): 0 samples\n",
      "Confidence Interval Very high (0.8, 1.0): 0 samples\n",
      "\n",
      "FALSE POSITIVES\n",
      "Confidence Interval Very low (0.0, 0.2): 0 samples\n",
      "Confidence Interval Low (0.2, 0.4): 0 samples\n",
      "Confidence Interval Medium (0.4, 0.6): 69 samples\n",
      "Confidence Interval High (0.6, 0.8): 123 samples\n",
      "Confidence Interval Very high (0.8, 1.0): 54 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11892/1470426946.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_classes'] = en_test_preds\n",
      "/tmp/ipykernel_11892/1470426946.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_probs'] = en_test_probs\n"
     ]
    }
   ],
   "source": [
    "# Predict over the test dataset\n",
    "en_test_probs = (en_bilstm_model.predict(en_test_matrix))\n",
    "en_test_preds = (en_bilstm_model.predict(en_test_matrix) >= 0.5).astype('int32')\n",
    "\n",
    "# Insert the predicted classes and probabilities into the test dataset\n",
    "en_test_df['task1_pred_classes'] = en_test_preds\n",
    "en_test_df['task1_pred_probs'] = en_test_probs\n",
    "\n",
    "print('FALSE NEGATIVES')\n",
    "false_negatives_df = en_test_df[(en_test_df['task1'] == 1) & (en_test_df['task1_pred_classes'] == 0)]\n",
    "analyze_predicted_probs(\n",
    "    dataset=false_negatives_df,\n",
    "    probs_col='task1_pred_probs')\n",
    "\n",
    "print('\\nFALSE POSITIVES')\n",
    "false_positives_df = en_test_df[(en_test_df['task1'] == 0) & (en_test_df['task1_pred_classes'] == 1)]\n",
    "analyze_predicted_probs(\n",
    "    dataset=false_positives_df,\n",
    "    probs_col='task1_pred_probs')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se cruzan las muestras positivas erróneamente clasificadas con las categorías sexistas a las que pertenecen se observa una tendencia idéntica a la vista en el entrenamiento y validación de modelos con Regresión Logística. La **mayoría de los documentos sexistas pertenecen a categorías sumamente complicadas de detectar** por clasificadores automáticos debido a su falta de características concretas que permitan asimilar su patrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ideological-inequality</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stereotyping-dominance</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misogyny-non-sexual-violence</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexual-violence</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objectification</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id\n",
       "task2                            \n",
       "ideological-inequality        121\n",
       "stereotyping-dominance         96\n",
       "misogyny-non-sexual-violence   86\n",
       "sexual-violence                56\n",
       "objectification                39"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives_df.groupby(['task2']).count().filter(['id']).sort_values(by=['id'], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente combinando los falsos positivos y negativos con el análisis de detección de emociones realizado se descubren dos principales emociones que aglutinan la mayoría de documentos erróneamente clasificados: ***anger*** y ***joy***. Tras una inspección visual de nuevo he podido encontrar conclusiones similares a las alcanzadas con los modelos de Regresión Logística, siendo un **alto porcentaje de documentos irónicos los predominantes en la emoción *anger*, mientras que los textos clasificados en la emoción *joy* contienen terminología positiva mayoritariamente aunque sus significados son muy negativos y sexistas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE NEGATIVES\n",
      "Emotion: fear - No. of texts: 36\n",
      "Emotion: surprise - No. of texts: 7\n",
      "Emotion: joy - No. of texts: 97\n",
      "Emotion: love - No. of texts: 6\n",
      "Emotion: anger - No. of texts: 186\n",
      "Emotion: sadness - No. of texts: 66\n",
      "\n",
      "FALSE POSITIVES\n",
      "Emotion: fear - No. of texts: 30\n",
      "Emotion: surprise - No. of texts: 5\n",
      "Emotion: joy - No. of texts: 76\n",
      "Emotion: love - No. of texts: 2\n",
      "Emotion: anger - No. of texts: 107\n",
      "Emotion: sadness - No. of texts: 26\n"
     ]
    }
   ],
   "source": [
    "print('FALSE NEGATIVES')\n",
    "map_texts_to_emotions(\n",
    "    text_ids=list(false_negatives_df['id'].values),\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "print('\\nFALSE POSITIVES')\n",
    "map_texts_to_emotions(\n",
    "    text_ids=list(false_positives_df['id'].values),\n",
    "    is_test=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00f7dc61815a6da5453fee0a1d7c3baaa88d552412e55cf65ecdf10d17265d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

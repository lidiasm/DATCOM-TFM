{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicabilidad en Inteligencia Artificial\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "Debido al incremento exponencial del desarrollo y la integración de sistemas inteligentes en actividades de diversa naturaleza y frecuencia, la comprensión de su funcionamiento resulta fundamental por diversos motivos. \n",
    "En primer lugar si un modelo pretende **desempeñar un papel fundamental como una herramienta para ayudar a la toma de decisiones**, su modo de razonamiento debe ser fácilmente entendible por un ser humano tradicional. Así se puede analizar su **comportamiento** para observar rasgos indeseados que poder corregir, asegurar que sus pilares se encuentran alineados con los objetivos del problema que aborda, que cumple una determinada **ética** establecida en torno a las soluciones que propone, además de medidas de seguridad críticas con las que controlar la **calidad** de las mismas. \n",
    "\n",
    "De este modo en este notebook se pretende aplicar distintas técnicas de explicabilidad con la que comprender más detalladamente la conducta característica de los clasificadores elaborados para la detección de textos sexistas.\n",
    "\n",
    "### 1.1. Tipos de explicabilidad\n",
    "\n",
    "* **Modelos agnósticos locales**. Esta categoría de técnicas se pueden emplear sobre cualquier tipo de modelo de caja negra aunque únicamente se centran en una sola muestra."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estructura del notebook\n",
    "\n",
    "1. Introducción a la Explicabilidad en Inteligencia Artificial\n",
    "2. Estructura del notebook\n",
    "3. Instalación y carga de librerías\n",
    "4. Lectura y carga de datos procesados\n",
    "5. Técnicas de explicabilidad\n",
    "6. Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instalación y carga de librerías\n",
    "\n",
    "Este apartado tiene como único propósito cargar las librerías y dependencias necesarias para la ejecución de este notebook, así como las funciones propiamente desarrolladas. Previo a ello deberán ser instaladas bien ejecutando el script *setup.sh* mediante el comando `bash setup.sh` con permisos de ejecución en distribuciones Linux, o bien ejecutando el compando `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:55:05.161588: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 13:55:05.541508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-17 13:55:05.541548: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-17 13:55:06.861229: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-17 13:55:06.861344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-17 13:55:06.861353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Import encoding functions\n",
    "from encoding import *\n",
    "\n",
    "# pandas: to read the datasets\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: to work with predicted probabilities\n",
    "import numpy as np\n",
    "\n",
    "# skelearn: to encode documents\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# pickle: to load Logistic Regression models\n",
    "import pickle \n",
    "\n",
    "# keras: to load pre-trained models\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# lime: to create local explanations\n",
    "import lime\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# random: to choose random samples\n",
    "from random import randrange"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lectura y carga de datos procesados\n",
    "\n",
    "En esta sección se pretende leer y cargar los datos de entrenamiento y test ya procesados a los que se les ha aplicado las siguientes técnicas de tratamiento de documentos:\n",
    "\n",
    "  - Elimina URLs.\n",
    "  - Elimina usuarios mencionados.\n",
    "  - Elimina caracteres especiales, no alfabéticos y signos de puntuación.\n",
    "  - Convierte todos los caracteres en minúsculas.\n",
    "\n",
    "Tal y como se puede comprobar en los siguientes resultados las dimensiones de sendos conjuntos de datos se detallan a continuación:\n",
    "\n",
    "* Conjunto de entrenamiento: **6.865 muestras**.\n",
    "* Conjunto de validación: **4.296 muestras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset dimensions: (6865, 6)\n",
      "Test dataset dimensions: (4296, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read already processed EXIST datasets\n",
    "train_df = pd.read_csv('../data/proc_EXIST2021_train.csv')\n",
    "test_df = pd.read_csv('../data/proc_EXIST2021_test.csv')\n",
    "\n",
    "# Show the dimensions of the datasets\n",
    "print('Train dataset dimensions:', train_df.shape)\n",
    "print('Test dataset dimensions:', test_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Técnicas de explicabilidad\n",
    "\n",
    "### 5.1. LIME\n",
    "\n",
    "Se trata de un procedimiento que genera **explicaciones locales a una única muestra dentro de una determinada clase** cuyo objetivo consiste en determinar la relevancia de cada característica (palabra) proporcionada para su predicción. Para ello genera un **modelo lineal** que se entrena en base a perturbaciones generadas a partir de un ejemplo seleccionado y luego es evaluado dependiendo de la similitud entre las predicciones producidas y la real asociada a la entrada suministrada. Esta tarea es posible mediante el uso de la librería *lime* de Python a la que se le debe proporcionar una muestra de ejemplo junto con una función que permite obtener la predicción de las perturbaciones creadas.\n",
    "\n",
    "Puesto que se trata de un método local a un ejemplo, se propone su aplicación en los conjuntos de **falsos positivos y negativos** analizados en notebooks anteriores con la idea de comprobar cuáles son los términos destacables que han liderado hacia una clasificación errónea. Como los volumenes de muestras son bastante considerables, se pretende seleccionar **diez ejemplos aleatoriamente de cada intervalo de confianza** para además detectar la existencia de características diferentes en función de la seguridad demostrada por parte del modelo al identificar cada dato de test.\n",
    "\n",
    "#### 5.1.1. Modelo inglés de Regresión Logística\n",
    "\n",
    "Comenzamos ejecutando este método sobre el mejor clasificador inglés de Regresión Logística encontrado cuya codificación se realizó transformando los textos en bolsas de palabras. A continuación se observa que este modelo se caracteriza por tener 213 falsos positivos y 438 falsos negativos, unas cifras de errores demasiado elevadas para considerarlo como una solución de calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false negatives: 438\n",
      "No. of false positives: 213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8388/2998631689.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_classes'] = en_lr_model.predict(X=en_test_bag_words)\n",
      "/tmp/ipykernel_8388/2998631689.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_probs'] = [max(prob) for prob in en_lr_model.predict_proba(X=en_test_bag_words)]\n"
     ]
    }
   ],
   "source": [
    "# Load a Logistic Regression model specialized in English\n",
    "en_lr_model = pickle.load(open('../models/multileng_lr_models/en_bag_words_model.sav', 'rb'))\n",
    "\n",
    "# Filter the train documents by language\n",
    "en_train_df = train_df[train_df['language'] == 'en']\n",
    "en_train_texts = list(en_train_df['clean_text'].values)\n",
    "\n",
    "# Filter the test documents by language\n",
    "en_test_df = test_df[test_df['language'] == 'en']\n",
    "en_test_texts = list(en_test_df['clean_text'].values)\n",
    "\n",
    "# Convert train and test documents to bag of words\n",
    "en_train_bag_words, en_test_bag_words = to_bag_of_words(\n",
    "    train_docs=en_train_texts, \n",
    "    test_docs=en_test_texts)\n",
    "\n",
    "# Predict over the test dataset\n",
    "en_test_df['task1_pred_classes'] = en_lr_model.predict(X=en_test_bag_words)\n",
    "en_test_df['task1_pred_probs'] = [max(prob) for prob in en_lr_model.predict_proba(X=en_test_bag_words)]\n",
    "\n",
    "# Get the indexes of the false negatives and positives\n",
    "en_fn_df = en_test_df[(en_test_df['task1'] == 1) & (en_test_df['task1_pred_classes'] == 0)]\n",
    "en_fp_df = en_test_df[(en_test_df['task1'] == 0) & (en_test_df['task1_pred_classes'] == 1)]\n",
    "\n",
    "print(f'No. of false negatives: {en_fn_df.shape[0]}')\n",
    "print(f'No. of false positives: {en_fp_df.shape[0]}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las conclusiones extraídas de la generación de explicaciones locales a un subconjunto de **falsos negativos** se presentan a continuación:\n",
    "\n",
    "* Los falsos negativos pertenecientes al más elevado intervalo de confianza otorga un grado de **no-sexismo a palabras sin significado** como pronombres, determinantes, preposiciones y verbos auxiliares, que pueden contrarrestar el efecto de terminología sexista. \n",
    "\n",
    "* Aquellos cometidos bajo un rango de confianza alto demuestran un notable grado de **ironía** con terminología positiva aunque con significados profundamente sexistas. Este fenómeno ya se intuía en el análisis exploratorio de datos que se realizó al comienzo de este proyecto.\n",
    "\n",
    "* Finalmente los falsos negativos que se encuentran dentro del intervalo moderado de confianza están caracterizados por su alta composición de **hashtags y errores ortográficos** que dificultan su análisis e identificación automáticos. No obstante, pese a haber tratado de detectar y corregir los términos gramaticalmente erróneos empleando diversas librerías, ninguna de ellas ha podido conseguir la mejora de la capacidad de predicción de los modelos de Regresión Logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LIME explainer object\n",
    "lime_explainer = LimeTextExplainer(class_names={\n",
    "    0: 'non-sexist',\n",
    "    1: 'sexist'\n",
    "})\n",
    "\n",
    "for pair in [(0.4, 0.6), (0.6, 0.8), (0.8, 1.1)]:\n",
    "    # Filter the false negatives by confidence interval\n",
    "    en_fn_subdf = en_fn_df[(en_fn_df['task1_pred_probs'] >= pair[0]) & \\\n",
    "        (en_fn_df['task1_pred_probs'] < pair[1])]\n",
    "    en_fn_subdf_texts = list(en_fn_subdf['clean_text'].values)\n",
    "\n",
    "    # Choose 10 distinct samples randomly\n",
    "    chosen_fn_texts = []\n",
    "    for iter in range(0, 10):\n",
    "        fn_index = randrange(len(en_fn_subdf_texts))\n",
    "        while (fn_index in chosen_fn_texts):\n",
    "            fn_index = randrange(len(en_fn_subdf_texts))\n",
    "\n",
    "        chosen_fn_texts.append(fn_index)\n",
    "\n",
    "    # Create explanations for each sample\n",
    "    def predict_en_lrm_model(sample: str):\n",
    "\n",
    "        # Train a CountVectorizer object based on train documents\n",
    "        bg_vectorizer = CountVectorizer()\n",
    "        bg_vectorizer.fit(raw_documents=en_train_texts)\n",
    "\n",
    "        # Encode the provided test sample \n",
    "        encoded_sample = bg_vectorizer.transform(raw_documents=sample).toarray()\n",
    "        \n",
    "        # Predict the probabilities for both classes\n",
    "        pred_prob = en_lr_model.predict_proba(X=encoded_sample)\n",
    "        return np.array(pred_prob)\n",
    "\n",
    "    for indx in chosen_fn_texts:\n",
    "        # Create a single explanation for a single test sample\n",
    "        lime_explanation = lime_explainer.explain_instance(\n",
    "            en_fn_subdf_texts[indx], \n",
    "            predict_en_lrm_model).show_in_notebook(text=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicando el mismo procedimiento anterior aunque aplicado a los **falsos positivos** se han podido descubrir las siguientes pesquisas:\n",
    "\n",
    "* Los falsos positivos de los dos intervalos superiores de confianza **contienen noticias y reivindaciones de usuarios contra los ataques y la violencia contra la mujer**. Como se detalló en el análisis exploratorio de datos, las temáticas del conjunto de test son bien distintas de las tratadas en el dataset de entrenamiento. El problema reside en que términos comunes como \"mujeres\", \"feminismo\", etc. son catalogados individualmente como sexistas y como consecuencia producen este comportamiento erróneo en el modelo.\n",
    "\n",
    "* Los falsos positivos situados en el intervalo moderado de confianza destacan por tratar **otros tópicos** en los que aparecen también palabras de género como \"mujeres\", \"marido\", entre otras que pese a ser clasificadas como sexistas su significado no es tal. De nuevo, este hecho fue descubierto durante el análisis exploratorio de datos inicial en el que ya se aventuraba las discrepancias de contenido entre ambos datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2. Modelo español de Regresión Logística\n",
    "\n",
    "A continuación se repite el estudio previo pero haciendo uso del mejor modelo español de Regresión Logística con sus correspondientes documentos en dicho idioma. En los siguientes resultados se puede apreciar que existen 462 documentos sexistas no detectados y 199 textos no sexistas erróneamente clasificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false negatives: 462\n",
      "No. of false positives: 199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8388/1758952928.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  es_test_df['task1_pred_classes'] = es_lr_model.predict(X=es_test_bag_words)\n",
      "/tmp/ipykernel_8388/1758952928.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  es_test_df['task1_pred_probs'] = [max(prob) for prob in es_lr_model.predict_proba(X=es_test_bag_words)]\n"
     ]
    }
   ],
   "source": [
    "# Load a Logistic Regression model specialized in Spanish\n",
    "es_lr_model = pickle.load(open('../models/multileng_lr_models/es_bag_words_model.sav', 'rb'))\n",
    "\n",
    "# Filter the train documents by language\n",
    "es_train_df = train_df[train_df['language'] == 'es']\n",
    "es_train_texts = list(es_train_df['clean_text'].values)\n",
    "\n",
    "# Filter the test documents by language\n",
    "es_test_df = test_df[test_df['language'] == 'es']\n",
    "es_test_texts = list(es_test_df['clean_text'].values)\n",
    "\n",
    "# Convert train and test documents to bag of words\n",
    "es_train_bag_words, es_test_bag_words = to_bag_of_words(\n",
    "    train_docs=es_train_texts, \n",
    "    test_docs=es_test_texts)\n",
    "\n",
    "# Predict over the test dataset\n",
    "es_test_df['task1_pred_classes'] = es_lr_model.predict(X=es_test_bag_words)\n",
    "es_test_df['task1_pred_probs'] = [max(prob) for prob in es_lr_model.predict_proba(X=es_test_bag_words)]\n",
    "\n",
    "# Get the indexes of the false negatives and positives\n",
    "es_fn_df = es_test_df[(es_test_df['task1'] == 1) & (es_test_df['task1_pred_classes'] == 0)]\n",
    "es_fp_df = es_test_df[(es_test_df['task1'] == 0) & (es_test_df['task1_pred_classes'] == 1)]\n",
    "\n",
    "print(f'No. of false negatives: {es_fn_df.shape[0]}')\n",
    "print(f'No. of false positives: {es_fp_df.shape[0]}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las deducciones descubiertas tras la visualización de diez muestras positivas clasificadas erróneamente seleccionadas aleatoriamente por cada intervalo de confianza, como se ha efectuado con el clasificador inglés, han sido idénticamente similares a las observadas previamente.\n",
    "\n",
    "Por otro lado en relación a los falsos positivos, es decir ejemplos negativos identificados como positivos, además de compartir las características descubiertas anteriormente también cabe destacar la **sexualización por parte del modelo de prendas femeninas**, como la falda, además de la no comprensión de terminología latinoamericana puesto que no se les asigna ninguna clase o valor por lo que se consideran neutros."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3. Modelo LSTM inglés\n",
    "\n",
    "En esta sección se cambia de arquitectura para generar exlicaciones locales utilizando el mejor modelo LSTM específico de documentos ingleses compuesto por capas bidireccionales. En los siguientes resultados se puede observar la existencia de más de 398 falsos negativos y 246 falsos positivos. A continuación se procede a muestrear diez ejemplos de cada conjunto por intervalo de confianza para analiar sus resultados, tal y como se realizó en los apartados previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data_as_matrixes(train_texts:list, test_texts: list, max_n_words: int, sequence_len: int):\n",
    "    '''\n",
    "    Function that creates and trains a Keras tokenizer based on the provided\n",
    "    train documents to encode the train and test data as numeric matrixes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_texts : list\n",
    "        A list of strings with the train documents to encode.\n",
    "    test_texts : list\n",
    "        A list of strings with the test documents to encode.\n",
    "    max_n_words : int\n",
    "        Maximum number of words to keep within the LSTM memory\n",
    "        based on computing the word frequency.\n",
    "    sequence_len : int\n",
    "        Maximum lenght of all sequences.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A\n",
    "    '''\n",
    "    # Create a tokenizer based on train texts\n",
    "    tokenizer = Tokenizer(num_words=max_n_words)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    # Transform each text into a numeric sequence\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    train_matrix = pad_sequences(\n",
    "        sequences=train_sequences, \n",
    "        maxlen=sequence_len)\n",
    "\n",
    "    # Tokenize the test documents using the prior trained tokenizer\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    test_matrix = pad_sequences(\n",
    "        sequences=test_sequences,\n",
    "        maxlen=sequence_len)\n",
    "    \n",
    "    return tokenizer, train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:20:55.146273: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-17 13:20:55.146531: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-17 13:20:55.146553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lidiasm): /proc/driver/nvidia/version does not exist\n",
      "2023-04-17 13:20:55.147093: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 6s 65ms/step\n",
      " 2/69 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5433/1486523555.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_probs'] = (en_bilstm_model.predict(en_test_matrix))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 4s 64ms/step\n",
      "No. of false negatives: 398\n",
      "No. of false positives: 246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5433/1486523555.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_test_df['task1_pred_classes'] = (en_bilstm_model.predict(en_test_matrix) >= 0.5).astype('int32')\n"
     ]
    }
   ],
   "source": [
    "# Number of words to retain in the LSTM memory\n",
    "MAX_N_WORDS = 1000\n",
    "\n",
    "# Max number of tokens per numeric sequence\n",
    "SEQUENCE_MAX_LEN = 100\n",
    "\n",
    "# Path to the multilanguage embedding file\n",
    "MULTILAN_EMBEDDINGS_FILE = '../en_es_embeddings/glove.twitter.27B.100d.txt'\n",
    "\n",
    "# Filter the train documents by language\n",
    "en_train_df = train_df[train_df['language'] == 'en']\n",
    "en_train_texts = list(en_train_df['clean_text'].values)\n",
    "\n",
    "# Filter the test documents by language\n",
    "en_test_df = test_df[test_df['language'] == 'en']\n",
    "en_test_texts = list(en_test_df['clean_text'].values)\n",
    "\n",
    "# Convert processed train and test documents into matrixes\n",
    "en_tokenizer, en_train_matrix, en_test_matrix = encode_data_as_matrixes(\n",
    "    train_texts=en_train_texts,\n",
    "    test_texts=en_test_texts,\n",
    "    max_n_words=MAX_N_WORDS,\n",
    "    sequence_len=SEQUENCE_MAX_LEN\n",
    ")\n",
    "\n",
    "# Load a pretrained BiLSTM model trained over English texts\n",
    "en_bilstm_model = load_model('../models/en_lstm_models/en_bilstm_model_2L_128N_32BS.h5')\n",
    "\n",
    "# Predict over the test dataset\n",
    "en_test_df['task1_pred_probs'] = (en_bilstm_model.predict(en_test_matrix))\n",
    "en_test_df['task1_pred_classes'] = (en_bilstm_model.predict(en_test_matrix) >= 0.5).astype('int32')\n",
    "\n",
    "# Get the indexes of the false negatives and positives\n",
    "en_fn_df = en_test_df[(en_test_df['task1'] == 1) & (en_test_df['task1_pred_classes'] == 0)]\n",
    "en_fp_df = en_test_df[(en_test_df['task1'] == 0) & (en_test_df['task1_pred_classes'] == 1)]\n",
    "\n",
    "print(f'No. of false negatives: {en_fn_df.shape[0]}')\n",
    "print(f'No. of false positives: {en_fp_df.shape[0]}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del código propuesto anteriormente únicamente se ha modificado la función que calcula las predicciones para las perturbaciones basadas en una muestra de test ya que es requisito indispensable obtener una probabilidad para cada clase aunque el método de Keras únicamente devuelve la más elevada. Tras inspeccionar los resultados de los **falsos negativos** se pueden concluir que se repiten los fenómenos analizados en los modelos anteriores y que de nuevo se han visualizado ciertos **términos que son claramente sexistas pero no han sido tratados como tal**, lo que ha contribuido a cometer clasificaciones erroneas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LIME explainer object\n",
    "lime_explainer = LimeTextExplainer(class_names={\n",
    "    0: 'non-sexist',\n",
    "    1: 'sexist'\n",
    "})\n",
    "\n",
    "for pair in [(0.4, 0.6), (0.2, 0.4), (-0.1, 0.2)]:\n",
    "    # Filter the false negatives by confidence interval\n",
    "    en_fn_subdf = en_fn_df[(en_fn_df['task1_pred_probs'] >= pair[0]) & \\\n",
    "        (en_fn_df['task1_pred_probs'] < pair[1])]\n",
    "    en_fn_subdf_texts = list(en_fn_subdf['clean_text'].values)\n",
    "\n",
    "    # Choose 10 distinct samples randomly\n",
    "    chosen_fn_texts = []\n",
    "    for iter in range(0, 10):\n",
    "        fn_index = randrange(len(en_fn_subdf_texts))\n",
    "        while (fn_index in chosen_fn_texts):\n",
    "            fn_index = randrange(len(en_fn_subdf_texts))\n",
    "\n",
    "        chosen_fn_texts.append(fn_index)\n",
    "\n",
    "    # Create explanations for each sample\n",
    "    def encode_predict_lstm_model(sample: str):\n",
    "\n",
    "        # Tokenize the test documents using the prior trained tokenizer\n",
    "        sample_sequence = en_tokenizer.texts_to_sequences(sample)\n",
    "\n",
    "        # Transform each numeric sequence into a 2D vector\n",
    "        encoded_sample = pad_sequences(\n",
    "            sequences=sample_sequence,\n",
    "            maxlen=SEQUENCE_MAX_LEN)\n",
    "            \n",
    "        # Predict the probability for the max class\n",
    "        one_class_pred_probs = en_bilstm_model.predict(encoded_sample)\n",
    "\n",
    "        # Calculate the probability for each class\n",
    "        biclass_pred_probs = [np.array([1-record[0], record[0]]) for record in one_class_pred_probs]\n",
    "        return np.array(biclass_pred_probs)\n",
    "    \n",
    "\n",
    "    for indx in chosen_fn_texts:\n",
    "        # Create a single explanation for a single test sample\n",
    "        lime_explanation = lime_explainer.explain_instance(\n",
    "            en_fn_subdf_texts[indx], \n",
    "            predict_en_lrm_model).show_in_notebook(text=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En referencia a los **falsos positivos** existen una gran multitud de similitudes con respecto al análisis previo de muestras negativas erróneamente clasificadas, de nuevo he podido descubrir textos que aluden a otras temáticas y que han sido categorizados como positivos por contener palabras de género como \"woman\", \"women\", \"men\", etc. Sin embargo, un fenómeno muy destacable ha sido el hecho de encontrar documentos que contienen **negativas de términos sexistas** pero que han sido identificados como positivos puesto que el modelo no ha sido capaz de observar la expresión en su conjunto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4. Modelo LSTM español\n",
    "\n",
    "A continuación se procede a replicar el procedimiento analítico anterior aunque sobre el mejor modelo LSTM encontrado para documentos en español. Tal y como se aprecia en los siguientes resultados, dispone de 392 falsos negativos y 210 falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:55:30.692132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-17 13:55:30.692380: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-17 13:55:30.692396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lidiasm): /proc/driver/nvidia/version does not exist\n",
      "2023-04-17 13:55:30.692890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 3s 34ms/step\n",
      " 3/67 [>.............................] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4270/702147442.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  es_test_df['task1_pred_probs'] = (es_lstm_model.predict(es_test_matrix))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 2s 32ms/step\n",
      "No. of false negatives: 392\n",
      "No. of false positives: 210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4270/702147442.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  es_test_df['task1_pred_classes'] = (es_lstm_model.predict(es_test_matrix) >= 0.5).astype('int32')\n"
     ]
    }
   ],
   "source": [
    "# Number of words to retain in the LSTM memory\n",
    "MAX_N_WORDS = 1000\n",
    "\n",
    "# Max number of tokens per numeric sequence\n",
    "SEQUENCE_MAX_LEN = 100\n",
    "\n",
    "# Path to the multilanguage embedding file\n",
    "MULTILAN_EMBEDDINGS_FILE = '../en_es_embeddings/glove.twitter.27B.100d.txt'\n",
    "\n",
    "# Filter the train documents by language\n",
    "es_train_df = train_df[train_df['language'] == 'es']\n",
    "es_train_texts = list(es_train_df['clean_text'].values)\n",
    "\n",
    "# Filter the test documents by language\n",
    "es_test_df = test_df[test_df['language'] == 'es']\n",
    "es_test_texts = list(es_test_df['clean_text'].values)\n",
    "\n",
    "# Convert processed train and test documents into matrixes\n",
    "es_tokenizer, es_train_matrix, es_test_matrix = encode_data_as_matrixes(\n",
    "    train_texts=es_train_texts,\n",
    "    test_texts=es_test_texts,\n",
    "    max_n_words=MAX_N_WORDS,\n",
    "    sequence_len=SEQUENCE_MAX_LEN\n",
    ")\n",
    "\n",
    "# Load a pretrained BiLSTM model trained over English texts\n",
    "es_lstm_model = load_model('../models/es_lstm_models/es_lstm_3L_1286432N_16BS.h5')\n",
    "\n",
    "# Predict over the test dataset\n",
    "es_test_df['task1_pred_probs'] = (es_lstm_model.predict(es_test_matrix))\n",
    "es_test_df['task1_pred_classes'] = (es_lstm_model.predict(es_test_matrix) >= 0.5).astype('int32')\n",
    "\n",
    "# Get the indexes of the false negatives and positives\n",
    "es_fn_df = es_test_df[(es_test_df['task1'] == 1) & (es_test_df['task1_pred_classes'] == 0)]\n",
    "es_fp_df = es_test_df[(es_test_df['task1'] == 0) & (es_test_df['task1_pred_classes'] == 1)]\n",
    "\n",
    "print(f'No. of false negatives: {es_fn_df.shape[0]}')\n",
    "print(f'No. of false positives: {es_fp_df.shape[0]}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los documentos submuestreados para una inspección visual y una explicabilidad local de los **falsos negativos** han apuntado hacia nuevos fenómenos explicativos del pésimo comportamiento del modelo. En primer lugar existen textos que no contienen terminología sexista pero sí que pertenecen a esta clase. Sin embargo, desde una perspectiva técnica y automática no contienen pistas que hagan pensar que se trata de muestras positivas, para ello sería necesario un **mayor nivel de entendimiento del lenguaje natural** por parte del modelo que se asimilase al del humano. Por otro lado también son ampliamente utilizados **conceptos informales y casuales**, que no se encuentran comunmente en los diccionarios oficiales de idiomas, y que por tanto no son reconocidos automáticamente provocando una pérdida de información vital.\n",
    "\n",
    "No obstante en el estudio de los **falsos positivos** las pesquisas obtenidas son las ya conocidas hasta el momento con documentos con terminología propia de la temática considerada como sexista liderando los fallos cometidos, así como reivindicaciones con expresiones sexistas pero con un significado positivo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusiones generales\n",
    "\n",
    "* En primer lugar cabe destacar el hecho de que LIME únicamente analiza términos individuales en lugar de conjuntos de palabras o expresiones que podría ser más útil ya que conceptos por sí solos pueden no ser sexistas a no ser que se encuentren acompañados de otros que le otorguen ese significado, como violencia de género.\n",
    "\n",
    "* En los modelos de Regresión Logística y LSTM se ha podido descubrir que **terminología que debía ser neutra**, como pronombres, determinantes, preposiciones, se les ha asignado un valor no sexista que contrarresta, por su elevado volumen de aparación, a los conceptos que sí lo son provocando una multitud de muestras erróneamente clasificadas. Igualmente ocurre con **palabras comunes a este tópico**, como mujeres, marido, hombres, que son tratadas como sexistas de forma individual lo que conlleva también un considerable número de fallos.\n",
    "\n",
    "* Otra muestra más del trabajo que queda por realizar para aumentar el nivel de comprensión del lenguaje natural por modelos automáticos reside en aquellos documentos que muestran un **elevado grado de ironía o contienen negaciones de expresiones sexistas** que son categorizados dentro de la clase positiva.\n",
    "\n",
    "* Finalmente se ha descubierto que tanto los hashtags como los errores gramaticales producen una falta de información, severa en ciertos documentos, que provocan la pérdida de información liderando hacia una clasificación errónea de las muestras. Ambos fenómenos se encuentran más presentes en los ejemplos erróneamente clasificados bajo **intervalos moderados y bajos de confianza**, puesto que en estos casos el modelo apenas dispone de términos útiles en los que fundamentar su decisión y por ende se muestra más inseguro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

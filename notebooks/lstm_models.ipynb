{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos LSTM\n",
    "\n",
    "## 1. Introducción a LSTM\n",
    "\n",
    "LSTM es un acrónimo de *Long-Short Term Memory* y representa a un **subtipo de RNN** (*Recurrent Neural Network*) capaz de **retener información relevante** sobre datos ya procesados que ayude al procesamiento de nuevas secuencias de datos completas. Su arquitectura se encuentra compuesta a su vez por tres redes neuronales:\n",
    "\n",
    "* ***Forget Gate***: este primer modelo es el encargado de filtrar qué información previa es útil para su almacenamiento y qué datos ya no son útiles para futuras iteraciones. \n",
    "\n",
    "* ***Input Gate***: esta segunda red trata de determinar el valor que presentan los datos entrantes para resolver la tarea de clasificación.\n",
    "\n",
    "* ***Output Gate***: finalmente esta red calcula las salidas del modelo LSTM que dependerán de la tarea de clasificación que se pretende abordar.\n",
    "\n",
    "### 1.1. Condiciones de uso\n",
    "\n",
    "Dependiendo del framework que se pretenda utilizar (Tensorflow, Keras, Pytorch) existen diferentes tratamientos de datos y requisitos de implementación que se deben cumplir al definir la arquitectura, entrenamiento y validación de modelos. En mi caso particular he optado por utilizar **Keras** debido a la experiencia previa que tengo con la librería y a su facilidad de uso. \n",
    "\n",
    "1. **Procesamiento y limpieza** de los documentos.\n",
    "\n",
    "2. **Tokenización** de los documentos especificando un token para aquellos términos que no sean reconocidos dentro de un vocabulario de palabras.\n",
    "\n",
    "3. **Codificación** numérica en forma de matrices secuenciales de valores. \n",
    "\n",
    "5. **Normalización** de las secuencias numéricas para establecer un mismo tamaño fijo, completando con ceros aquellas de menor longitud y separando en varias secuencias aquellas que dispongan de un mayor tamaño.\n",
    "\n",
    "6. Definición de la arquitectura de un **modelo** e instanciación para su posterior entrenamiento y validación.\n",
    "\n",
    "### 1.2. Casos de uso\n",
    "\n",
    "* Detección y extracción de patrones en secuencias de datos.\n",
    "* Modelado del lenguaje natural.\n",
    "* Traducción de texto.\n",
    "* Reconocimiento de textos manuscritos.\n",
    "* Generación de imágenes mediante mecanismos de atención.\n",
    "* Sistemas de preguntas y respuestas.\n",
    "* Conversión de vídeo a texto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estructura del notebook\n",
    "\n",
    "1. Introducción a LSTM\n",
    "2. Estructura del notebook\n",
    "3. Instalación y carga de librerías\n",
    "4. Lectura y carga de datos\n",
    "5. Experimentos y modelos\n",
    "6. Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instalación y carga de librerías\n",
    "\n",
    "Este apartado tiene como único propósito cargar las librerías y dependencias necesarias para la ejecución de este notebook, así como las funciones propiamente desarrolladas. Previo a ello deberán ser instaladas bien ejecutando el script *setup.sh* mediante el comando `bash setup.sh` con permisos de ejecución en distribuciones Linux, o bien ejecutando el compando `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 22:39:21.556485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-03 22:39:22.023885: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-03 22:39:22.023914: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-03 22:39:23.323502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-03 22:39:23.323588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-03 22:39:23.323597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-03 22:39:25.937227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-03 22:39:25.937465: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-03 22:39:25.937483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lidiasm): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "# Import data read and compute functions\n",
    "from data import read_train_dataset, read_test_dataset\n",
    "\n",
    "# Import text preprocess functions\n",
    "from processing import *\n",
    "\n",
    "# numpy: to work with numeric codifications and embeddings\n",
    "import numpy as np\n",
    "\n",
    "# keras: to define and build LSTM models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import LSTM, Activation, Dense, Input, Embedding\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# sklearn: to plot a confusion matrix per trained model\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# matplotlib: to plot charts\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lectura y carga de datos originales\n",
    "\n",
    "En esta sección se pretende **cargar los datasets de entrenamiento y validación** procedentes de los correspondientes ficheros situados en la carpeta *data*. Al tener un **formato TSV** se deben leer como tablas aunque posteriormente se trabaje con ellos en formato *dataframe*. \n",
    "\n",
    "Tal y como se puede comprobar en los siguientes resultados las dimensiones de sendos conjuntos de datos se detallan a continuación:\n",
    "\n",
    "* Conjunto de entrenamiento: **6.977 muestras**.\n",
    "* Conjunto de validación: **4.368 muestras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset dimensions: (6977, 7)\n",
      "Test dataset dimensions: (4368, 7)\n"
     ]
    }
   ],
   "source": [
    "# Read EXIST datasets\n",
    "train_df = read_train_dataset()\n",
    "test_df = read_test_dataset()\n",
    "\n",
    "# Show the dimensions of the datasets\n",
    "print(\"Train dataset dimensions:\", train_df.shape)\n",
    "print(\"Test dataset dimensions:\", test_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimentos y modelos\n",
    "\n",
    "Esta sección pretende detallar los experimentos que se realizan a través de la combinación de diferentes técnicas de procesamiento de textos, codificación de documentos y arquitecturas de modelos LSTM. Como se trata de **experimentos no determinísticos**, es decir, los resultados difieren en varias ejecuciones aún con la misma configuración, la estrategia a seguir consiste en realizar **30 iteraciones de cada experimento** para luego calcular la **media de accuracy y AUC**, las métricas de evaluación escogidas para medir la calidad de un clasificador. \n",
    "\n",
    "Por lo tanto las siguientes secciones contienen los detalles del conjunto de experimentos realizados y las conclusiones comparativas alcanzadas, incluyendo el código, la configuración y los resultados únicamente del experimento con mejor rendimiento con respecto a las métricas de evaluación mencionadas.\n",
    "\n",
    "Previo al comienzo de la experimentación se definen tres funciones comunes para el tratamiento y codificación de documentos, carga de embeddings pre-entrenados y validación de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_matrix(\n",
    "    max_n_words: int, sequence_len: int, \n",
    "    lemm: bool = False, stemm: bool = False):\n",
    "    \"\"\"\n",
    "    Process the train and test documents to then convert them\n",
    "    into numeric sequence matrixes so the datasets can be\n",
    "    used to train a LSTM model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_n_words : int\n",
    "        Maximum number of words to keep within the LSTM memory\n",
    "        based on computing the word frequency.\n",
    "    sequence_len : int\n",
    "        Maximum lenght of all sequences.\n",
    "    lemm : bool (optional)\n",
    "        True to apply lemmatization to the train and test documents.\n",
    "    stemm : bool (optional)\n",
    "        True to apply stemming to the train and test documents.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary with the following keys:\n",
    "        - 'tokenizer': a Keras Tokenizer object based on the train documents\n",
    "        that contains the vocabulary to then be used to create the embeddings.\n",
    "        - 'train_matrix', 'test_matrix': the numeric sequence matrixes\n",
    "        after converting the train and test documents.\n",
    "        - 'train_labels', 'test_labels': two numeric lists which contains\n",
    "        the encoded class labels for train and test datasets.\n",
    "    \"\"\"\n",
    "    # Process train and test text documents\n",
    "    processed_df = process_encode_datasets(\n",
    "        train_df=train_df, \n",
    "        test_df=test_df,\n",
    "        lemm=lemm, \n",
    "        stemm=stemm\n",
    "    )\n",
    "\n",
    "    # Processed train texts and encoded train labels \n",
    "    train_texts = list(processed_df[\"train_df\"][\"cleaned_text\"].values)\n",
    "    train_labels = processed_df[\"encoded_train_labels\"]\n",
    "\n",
    "    # Processed test texts and encoded test labels\n",
    "    test_texts = list(processed_df[\"test_df\"][\"cleaned_text\"].values)\n",
    "    test_labels = processed_df[\"encoded_test_labels\"]\n",
    "\n",
    "    # Createa a tokenizer based on train texts\n",
    "    tokenizer = Tokenizer(num_words=max_n_words)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    # Transform each text into a numeric sequence\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    train_matrix = pad_sequences(\n",
    "        sequences=train_sequences, \n",
    "        maxlen=sequence_len)\n",
    "\n",
    "    # Tokenize the test documents using the prior trained tokenizer\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "    # Transform each numeric sequence into a 2D vector\n",
    "    test_matrix = pad_sequences(\n",
    "        sequences=test_sequences,\n",
    "        maxlen=sequence_len)\n",
    "\n",
    "    return {\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"train_matrix\": train_matrix,\n",
    "        \"train_labels\": train_labels,\n",
    "        \"test_matrix\": test_matrix,\n",
    "        \"test_labels\": test_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(embedding_file: str, tokenizer: Tokenizer, sequence_len: int):\n",
    "    \"\"\"\n",
    "    Load the embeddings stored in the provided file to then\n",
    "    create a matrix with the numeric encoding of each\n",
    "    available word within the tokenizer vocabulary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding_file : str\n",
    "        The path to the file which contains a set of embeddings\n",
    "    tokenizer : Tokenizer (Keras)\n",
    "        A trained Keras tokenizer which contains the vocabulary\n",
    "        of the documents to use during the training of models\n",
    "    sequence_len : int\n",
    "        Maximum lenght of all embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A Numpy ndarray which represents an embedding matrix.\n",
    "    \"\"\"\n",
    "    # Load the embeddings stored in a TXT file\n",
    "    embedding_file = open(embedding_file)\n",
    "\n",
    "    # Store each word with its embeddings\n",
    "    embeddings_index = {\n",
    "        line.split()[0]:np.asarray(line.split()[1:], dtype=\"float32\") \n",
    "        for line in embedding_file\n",
    "    }\n",
    "\n",
    "    # Initialize the embedding matrix with zeros\n",
    "    embedding_matrix = np.zeros(shape=(len(tokenizer.word_index)+1, sequence_len))\n",
    "\n",
    "    # Complete the matrix with the prior loaded embeddings\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        # Search for the embeddings of each word\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "\n",
    "        # Words not found will be zeros\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_lstm_model(\n",
    "    model: Model, \n",
    "    train_matrix: np.ndarray, train_labels: list, \n",
    "    test_matrix: np.ndarray, test_labels: list,\n",
    "    metrics_filename: str = None, conf_matrix_filename: str = None):\n",
    "    \"\"\"\n",
    "    Evaluates the provided trained LSTM model over the \n",
    "    train and test datasets to get the accuracy, AUC and\n",
    "    a confusion matrix. To create the predictions for a\n",
    "    binary classification a threshold has been set:\n",
    "        - <= 0.5 represents the negative class (non-sexist).\n",
    "        - > 0.5 represents the positive class (sexist).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Keras model\n",
    "        A trained Keras model to be evaluated.\n",
    "    train_matrix : Numpy ndarray\n",
    "        A numeric sequence matrix with the trained documents.\n",
    "    train_labels : list\n",
    "        A numeric list with the class labels of the train dataset.\n",
    "    test_matrix : Numpy ndarray\n",
    "        A numeric sequence matrix with the test documents.\n",
    "    test_labels : list\n",
    "        A numeric list with the class labels of the test dataset.\n",
    "    metrics_filename : str (optional)\n",
    "        A path and filename to save the metrics over the \n",
    "        train and test datasets in a TXT file.\n",
    "    conf_matrix_filename : str (optional)\n",
    "        A path and filename to save the confusion matrix in\n",
    "        a PNG image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    # Compute and print the accuracy and AUC over train\n",
    "    train_acc = model.evaluate(\n",
    "        x=train_matrix, \n",
    "        y=np.array(train_labels))\n",
    "\n",
    "    print(f\"Accuracy over train dataset: {train_acc[1]}\")\n",
    "    print(f\"AUC over train dataset: {train_acc[2]}\\n\")\n",
    "\n",
    "    # Compute and print the accuracy and AUC over test\n",
    "    test_acc = model.evaluate(\n",
    "        x=test_matrix, \n",
    "        y=np.array(test_labels))\n",
    "\n",
    "    print(f\"Accuracy over test dataset: {test_acc[1]}\")\n",
    "    print(f\"AUC over test dataset: {test_acc[2]}\")\n",
    "\n",
    "    # Generate class label predictions over the test dataset\n",
    "    # Class 0 ~ <= 0.5 | Class 1 ~ > 0.5\n",
    "    test_preds = (model.predict(test_matrix) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Plot the confusion matrix \n",
    "    ConfusionMatrixDisplay(\n",
    "        confusion_matrix=confusion_matrix(\n",
    "            np.array(test_labels), \n",
    "            np.array(test_preds)), \n",
    "        display_labels=[\"Non-sexist\", \"Sexist\"]) \\\n",
    "    .plot()    \n",
    "\n",
    "    # Save the confusion matrix in an image\n",
    "    if (type(conf_matrix_filename) == str and\n",
    "        len(conf_matrix_filename) > 0):\n",
    "        plt.savefig(conf_matrix_filename)\n",
    "\n",
    "    # Save the metrics in a text file\n",
    "    if (type(metrics_filename) == str and\n",
    "        len(metrics_filename) > 0):\n",
    "        opened_file = open(metrics_filename, \"w\")\n",
    "        print(f\"Accuracy over train dataset: {train_acc[1]}\", file=opened_file) \n",
    "        print(f\"AUC over train dataset: {train_acc[2]}\\n\", file=opened_file) \n",
    "        print(f\"Accuracy over test dataset: {test_acc[1]}\", file=opened_file) \n",
    "        print(f\"AUC over test dataset: {test_acc[2]}\", file=opened_file) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Mejor experimento: LSTM básica\n",
    "\n",
    "En esta sección se muestra el código, los resultados y las conclusiones del mejor experimento obtenido con la siguiente **arquitectura LSM básica**.\n",
    "\n",
    "  - 1 capa de entrada: para proporcionar la matriz de datos.\n",
    "  - 1 capa de embeddings: para proporcionar los embeddings pre-entrenados de Glove 6B 50d.\n",
    "  - 1 capa LSTM: con 64 neuronas ocultas para la extracción de características.\n",
    "  - 1 capa de salida: para unificar los datos de la capa anterior en una única salida. \n",
    "  - Función de activación: sigmoidal para calcular la probabilidad de pertenencia de cada muestra.\n",
    "\n",
    "#### Conclusiones\n",
    "\n",
    "* La aplicación de **lematización y/o stemming apenas mejora la capacidad predictiva** del modelo aunque sí aumenta el tiempo de ejecución, especialmente con la primera técnica. Por ello en el mejor experimento únicamente se aplica el siguiente **procesamiento básico**:\n",
    "\n",
    "  - Elimina caracteres especiales, no alfabéticos y signos de puntuación.\n",
    "  - Elimina hashtags y menciones de usuarios.\n",
    "  - Elimina *stopwords* en inglés y español.\n",
    "  - Elimina palabras sin vocales o compuestas por una única letra.\n",
    "  - <p>Convierte todos los caracteres a minúsculas.</p>\n",
    "\n",
    "* Se ha experimentado con los distintos ficheros de Glove embeddings y si bien se aprecia una **diferencia de más del 2% entre los dos primeros de 50 y 100**, los más pesados aumentan muchísimo el tiempo de ejecución mientras que la mejora con respecto a *accuracy* y AUC no es notable. Por lo tanto se ha optado por utilizar el fichero **glove.6b.100d.txt**.\n",
    "\n",
    "* Adicionalmente se ha experimenado con diversos valores para algunos parámetros como el tamaño del lote (*batch size*), el número de épocas de entrenamiento y criterios de parada temprana (*Early Stopping*). La configuración más propicia para el mejor experimento encontrado para la arquitectura básica mencionada se detalla a continuación:\n",
    "\n",
    "  - **Tamaño del lote: 128**. De entre los distintos experimentos realizados se han probado con valores de 64 y 32. Mientras que con el primero se ha conseguido igualar e incluso mejorar ligeramente las métricas de validación con un *batch size* de 128, el tiempo de ejecución aumenta a más del doble por lo que no parece merecer la pena.\n",
    "\n",
    "  - **Early stopping tras 15 iteraciones sin mejorar el valor de la métrica *AUC* en validación y recuperando los pesos del mejor modelo encontrado**, es decir, con el mínimo valor en esta métrica. Sin la aplicación de esta técnica se ha podido observar el fenómeno de **overfitting** que reduce ligeramente el valor de *accuracy* aunque drásticamente el valor de AUC.\n",
    "\n",
    "  - **Número máximo de iteraciones: 100**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix:\n",
      "[[  0   0   0 ... 210 761  92]\n",
      " [  0   0   0 ... 139 466 842]\n",
      " [  0   0   0 ... 255 256 183]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...  53 324 509]\n",
      " [  0   0   0 ...   2 726   7]]\n",
      "Train labels:[1, 0, 1, 0, 0]\n",
      "\n",
      "Test matrix:\n",
      "[[  0   0   0 ... 259 297  32]\n",
      " [  0   0   0 ... 109   3  48]\n",
      " [  0   0   0 ... 911 179 911]\n",
      " ...\n",
      " [  0   0   0 ... 522 413  97]\n",
      " [  0   0   0 ...   7  36 455]\n",
      " [  0   0   0 ...   5 102 166]]\n",
      "Test labels:[0, 0, 1, 1, 0]\n",
      "\n",
      "Glove 100 d embedding matrix:\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.83380997  0.94426    -0.011362   ... -0.15004     0.83995003\n",
      "   0.48519999]\n",
      " [ 0.52241999 -1.03410006  0.63090003 ... -0.7044      0.16324\n",
      "  -0.23263   ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "MAX_N_WORDS = 1000\n",
    "SEQUENCE_MAX_LEN = 100\n",
    "EMBEDDING_FILE_PATH = \"../embeddings/glove.6B.100d.txt\"\n",
    "APPLY_LEMMATIZATION = False \n",
    "APPLY_STEMMING = False \n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 100\n",
    "VALID_RATE = 0.2\n",
    "MODEL_CALLBACKS = [EarlyStopping(\n",
    "    monitor=\"val_auc\",\n",
    "    min_delta=0.001,\n",
    "    patience=15,\n",
    "    restore_best_weights=True)]\n",
    "LOSS_FUNCTION = \"binary_crossentropy\"\n",
    "OPTIMIZER = \"adam\"\n",
    "VALID_METRICS = [\"accuracy\", \"AUC\"]\n",
    "\n",
    "# Process the train and test documents as well as create\n",
    "# a tokenizer based on the processed train documents\n",
    "processed_data = get_train_test_matrix(\n",
    "    max_n_words=MAX_N_WORDS,\n",
    "    sequence_len=SEQUENCE_MAX_LEN,\n",
    "    lemm=False,\n",
    "    stemm=False\n",
    ")\n",
    "print(f\"Train matrix:\\n{processed_data['train_matrix']}\")\n",
    "print(f\"Train labels:{processed_data['train_labels'][0:5]}\")\n",
    "\n",
    "print(f\"\\nTest matrix:\\n{processed_data['test_matrix']}\")\n",
    "print(f\"Test labels:{processed_data['test_labels'][0:5]}\")\n",
    "\n",
    "# Load the embeddings stored in the defined file path\n",
    "# Encode the train matrix with these embeddings\n",
    "embedding_matrix = get_embedding_matrix(\n",
    "    embedding_file=EMBEDDING_FILE_PATH,\n",
    "    tokenizer=processed_data[\"tokenizer\"],\n",
    "    sequence_len=SEQUENCE_MAX_LEN\n",
    ")\n",
    "print(f\"\\nGlove 100 d embedding matrix:\\n{embedding_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 100, 100)          2415000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                42240     \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,457,305\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 2,415,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 8s 121ms/step - loss: 0.6595 - accuracy: 0.6096 - auc: 0.6301 - val_loss: 0.8212 - val_accuracy: 0.3438 - val_auc: 0.5490\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.6269 - accuracy: 0.6596 - auc: 0.6950 - val_loss: 0.8858 - val_accuracy: 0.3446 - val_auc: 0.5555\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 6s 139ms/step - loss: 0.6092 - accuracy: 0.6796 - auc: 0.7247 - val_loss: 0.8002 - val_accuracy: 0.4169 - val_auc: 0.5728\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 6s 143ms/step - loss: 0.5969 - accuracy: 0.6845 - auc: 0.7374 - val_loss: 0.7877 - val_accuracy: 0.4491 - val_auc: 0.5797\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 5s 118ms/step - loss: 0.5816 - accuracy: 0.6975 - auc: 0.7587 - val_loss: 0.7236 - val_accuracy: 0.5244 - val_auc: 0.5838\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.5694 - accuracy: 0.7097 - auc: 0.7706 - val_loss: 0.7926 - val_accuracy: 0.4792 - val_auc: 0.5915\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 6s 126ms/step - loss: 0.5579 - accuracy: 0.7140 - auc: 0.7809 - val_loss: 0.7869 - val_accuracy: 0.5007 - val_auc: 0.5959\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 5s 122ms/step - loss: 0.5409 - accuracy: 0.7339 - auc: 0.7991 - val_loss: 0.8664 - val_accuracy: 0.4864 - val_auc: 0.5986\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.5299 - accuracy: 0.7368 - auc: 0.8080 - val_loss: 0.7345 - val_accuracy: 0.5630 - val_auc: 0.6022\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.5145 - accuracy: 0.7515 - auc: 0.8213 - val_loss: 0.8257 - val_accuracy: 0.5136 - val_auc: 0.5932\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.5041 - accuracy: 0.7563 - auc: 0.8302 - val_loss: 0.8410 - val_accuracy: 0.5179 - val_auc: 0.6014\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.4829 - accuracy: 0.7669 - auc: 0.8470 - val_loss: 0.8892 - val_accuracy: 0.5150 - val_auc: 0.6016\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 5s 117ms/step - loss: 0.4722 - accuracy: 0.7775 - auc: 0.8529 - val_loss: 0.7698 - val_accuracy: 0.5688 - val_auc: 0.6022\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.4691 - accuracy: 0.7735 - auc: 0.8558 - val_loss: 0.9989 - val_accuracy: 0.4986 - val_auc: 0.6053\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.4512 - accuracy: 0.7895 - auc: 0.8682 - val_loss: 1.1617 - val_accuracy: 0.4441 - val_auc: 0.5946\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.4256 - accuracy: 0.8059 - auc: 0.8853 - val_loss: 0.9183 - val_accuracy: 0.5344 - val_auc: 0.6016\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.4146 - accuracy: 0.8151 - auc: 0.8910 - val_loss: 0.8714 - val_accuracy: 0.5487 - val_auc: 0.6051\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 0.3912 - accuracy: 0.8291 - auc: 0.9056 - val_loss: 0.9676 - val_accuracy: 0.5308 - val_auc: 0.6038\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.3755 - accuracy: 0.8339 - auc: 0.9126 - val_loss: 0.9790 - val_accuracy: 0.5330 - val_auc: 0.5988\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.3630 - accuracy: 0.8414 - auc: 0.9192 - val_loss: 1.1564 - val_accuracy: 0.4993 - val_auc: 0.5999\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 5s 108ms/step - loss: 0.3447 - accuracy: 0.8538 - auc: 0.9285 - val_loss: 1.1090 - val_accuracy: 0.5251 - val_auc: 0.6025\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.3277 - accuracy: 0.8597 - auc: 0.9355 - val_loss: 1.0604 - val_accuracy: 0.5509 - val_auc: 0.6016\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.3165 - accuracy: 0.8667 - auc: 0.9405 - val_loss: 1.1430 - val_accuracy: 0.5265 - val_auc: 0.5958\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.3070 - accuracy: 0.8683 - auc: 0.9439 - val_loss: 1.3063 - val_accuracy: 0.4964 - val_auc: 0.5941\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.2918 - accuracy: 0.8758 - auc: 0.9500 - val_loss: 1.1882 - val_accuracy: 0.5344 - val_auc: 0.5964\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.2790 - accuracy: 0.8830 - auc: 0.9551 - val_loss: 1.3607 - val_accuracy: 0.5057 - val_auc: 0.5907\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.2665 - accuracy: 0.8920 - auc: 0.9594 - val_loss: 1.3561 - val_accuracy: 0.5172 - val_auc: 0.5923\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 5s 108ms/step - loss: 0.2460 - accuracy: 0.8977 - auc: 0.9662 - val_loss: 1.4872 - val_accuracy: 0.5136 - val_auc: 0.5957\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 5s 108ms/step - loss: 0.2370 - accuracy: 0.9007 - auc: 0.9682 - val_loss: 1.4499 - val_accuracy: 0.5236 - val_auc: 0.5895\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.2345 - accuracy: 0.9031 - auc: 0.9690 - val_loss: 1.2732 - val_accuracy: 0.5387 - val_auc: 0.5816\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.2195 - accuracy: 0.9120 - auc: 0.9738 - val_loss: 1.3682 - val_accuracy: 0.5415 - val_auc: 0.5935\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.2117 - accuracy: 0.9151 - auc: 0.9755 - val_loss: 1.5099 - val_accuracy: 0.5265 - val_auc: 0.5897\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.2084 - accuracy: 0.9147 - auc: 0.9754 - val_loss: 1.5299 - val_accuracy: 0.5308 - val_auc: 0.5796\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 5s 105ms/step - loss: 0.1951 - accuracy: 0.9226 - auc: 0.9799 - val_loss: 1.5793 - val_accuracy: 0.5251 - val_auc: 0.5805\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.1877 - accuracy: 0.9260 - auc: 0.9814 - val_loss: 1.7506 - val_accuracy: 0.5057 - val_auc: 0.5786\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.1806 - accuracy: 0.9246 - auc: 0.9824 - val_loss: 1.5987 - val_accuracy: 0.5344 - val_auc: 0.5829\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.1871 - accuracy: 0.9267 - auc: 0.9804 - val_loss: 1.8778 - val_accuracy: 0.4971 - val_auc: 0.5609\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 5s 112ms/step - loss: 0.1825 - accuracy: 0.9283 - auc: 0.9818 - val_loss: 1.6480 - val_accuracy: 0.5122 - val_auc: 0.5869\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.1656 - accuracy: 0.9342 - auc: 0.9855 - val_loss: 1.5385 - val_accuracy: 0.5330 - val_auc: 0.5873\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.1580 - accuracy: 0.9364 - auc: 0.9871 - val_loss: 1.8634 - val_accuracy: 0.5057 - val_auc: 0.5768\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 5s 111ms/step - loss: 0.1606 - accuracy: 0.9337 - auc: 0.9860 - val_loss: 1.6048 - val_accuracy: 0.5487 - val_auc: 0.5743\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 5s 105ms/step - loss: 0.1896 - accuracy: 0.9204 - auc: 0.9788 - val_loss: 1.7726 - val_accuracy: 0.5236 - val_auc: 0.5805\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.1529 - accuracy: 0.9396 - auc: 0.9879 - val_loss: 1.8565 - val_accuracy: 0.5244 - val_auc: 0.5740\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 5s 108ms/step - loss: 0.1439 - accuracy: 0.9423 - auc: 0.9893 - val_loss: 2.1231 - val_accuracy: 0.5107 - val_auc: 0.5766\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.1346 - accuracy: 0.9468 - auc: 0.9909 - val_loss: 1.9860 - val_accuracy: 0.5236 - val_auc: 0.5777\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.1282 - accuracy: 0.9488 - auc: 0.9917 - val_loss: 2.0159 - val_accuracy: 0.5201 - val_auc: 0.5698\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.1268 - accuracy: 0.9482 - auc: 0.9916 - val_loss: 2.1685 - val_accuracy: 0.5143 - val_auc: 0.5742\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.1220 - accuracy: 0.9518 - auc: 0.9925 - val_loss: 2.1911 - val_accuracy: 0.5208 - val_auc: 0.5725\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 5s 125ms/step - loss: 0.1178 - accuracy: 0.9523 - auc: 0.9929 - val_loss: 2.2803 - val_accuracy: 0.5179 - val_auc: 0.5704\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 6s 140ms/step - loss: 0.1144 - accuracy: 0.9540 - auc: 0.9931 - val_loss: 2.2888 - val_accuracy: 0.5086 - val_auc: 0.5668\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 5s 116ms/step - loss: 0.1158 - accuracy: 0.9545 - auc: 0.9933 - val_loss: 2.1367 - val_accuracy: 0.5258 - val_auc: 0.5641\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 5s 123ms/step - loss: 0.1127 - accuracy: 0.9561 - auc: 0.9937 - val_loss: 2.5432 - val_accuracy: 0.4986 - val_auc: 0.5704\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 5s 116ms/step - loss: 0.1118 - accuracy: 0.9557 - auc: 0.9938 - val_loss: 2.5608 - val_accuracy: 0.5122 - val_auc: 0.5706\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 6s 139ms/step - loss: 0.1328 - accuracy: 0.9454 - auc: 0.9901 - val_loss: 2.1876 - val_accuracy: 0.5179 - val_auc: 0.5714\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 6s 145ms/step - loss: 0.1498 - accuracy: 0.9421 - auc: 0.9868 - val_loss: 2.2154 - val_accuracy: 0.5265 - val_auc: 0.5744\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 5s 112ms/step - loss: 0.1293 - accuracy: 0.9486 - auc: 0.9909 - val_loss: 2.1425 - val_accuracy: 0.5308 - val_auc: 0.5699\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 5s 118ms/step - loss: 0.1260 - accuracy: 0.9502 - auc: 0.9915 - val_loss: 2.4773 - val_accuracy: 0.5072 - val_auc: 0.5733\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 5s 124ms/step - loss: 0.1114 - accuracy: 0.9568 - auc: 0.9939 - val_loss: 2.2005 - val_accuracy: 0.5244 - val_auc: 0.5612\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 5s 123ms/step - loss: 0.1036 - accuracy: 0.9597 - auc: 0.9946 - val_loss: 2.4139 - val_accuracy: 0.5165 - val_auc: 0.5679\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 6s 130ms/step - loss: 0.0975 - accuracy: 0.9609 - auc: 0.9954 - val_loss: 2.3511 - val_accuracy: 0.5186 - val_auc: 0.5668\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 6s 132ms/step - loss: 0.0945 - accuracy: 0.9629 - auc: 0.9956 - val_loss: 2.5943 - val_accuracy: 0.5086 - val_auc: 0.5693\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 6s 141ms/step - loss: 0.0930 - accuracy: 0.9634 - auc: 0.9957 - val_loss: 2.6195 - val_accuracy: 0.5150 - val_auc: 0.5721\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 6s 134ms/step - loss: 0.0913 - accuracy: 0.9634 - auc: 0.9958 - val_loss: 2.5884 - val_accuracy: 0.5186 - val_auc: 0.5695\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 5s 108ms/step - loss: 0.0893 - accuracy: 0.9636 - auc: 0.9958 - val_loss: 2.6686 - val_accuracy: 0.5215 - val_auc: 0.5686\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 0.0876 - accuracy: 0.9651 - auc: 0.9961 - val_loss: 3.0002 - val_accuracy: 0.4979 - val_auc: 0.5711\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.0869 - accuracy: 0.9649 - auc: 0.9960 - val_loss: 2.6923 - val_accuracy: 0.5308 - val_auc: 0.5689\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.0848 - accuracy: 0.9663 - auc: 0.9964 - val_loss: 3.0804 - val_accuracy: 0.4943 - val_auc: 0.5681\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 5s 121ms/step - loss: 0.0971 - accuracy: 0.9633 - auc: 0.9946 - val_loss: 2.8086 - val_accuracy: 0.5251 - val_auc: 0.5777\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 5s 114ms/step - loss: 0.1184 - accuracy: 0.9534 - auc: 0.9916 - val_loss: 1.9522 - val_accuracy: 0.5473 - val_auc: 0.5744\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.1135 - accuracy: 0.9557 - auc: 0.9924 - val_loss: 2.1540 - val_accuracy: 0.5387 - val_auc: 0.5774\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.1156 - accuracy: 0.9548 - auc: 0.9925 - val_loss: 2.2934 - val_accuracy: 0.5337 - val_auc: 0.5709\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.0890 - accuracy: 0.9656 - auc: 0.9961 - val_loss: 2.3312 - val_accuracy: 0.5322 - val_auc: 0.5729\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 5s 113ms/step - loss: 0.0823 - accuracy: 0.9679 - auc: 0.9967 - val_loss: 2.4130 - val_accuracy: 0.5330 - val_auc: 0.5708\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 5s 114ms/step - loss: 0.0794 - accuracy: 0.9686 - auc: 0.9968 - val_loss: 2.5492 - val_accuracy: 0.5258 - val_auc: 0.5708\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.0783 - accuracy: 0.9694 - auc: 0.9970 - val_loss: 2.7830 - val_accuracy: 0.5179 - val_auc: 0.5705\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 5s 113ms/step - loss: 0.0765 - accuracy: 0.9690 - auc: 0.9970 - val_loss: 2.6795 - val_accuracy: 0.5258 - val_auc: 0.5691\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 0.0754 - accuracy: 0.9694 - auc: 0.9971 - val_loss: 2.6057 - val_accuracy: 0.5330 - val_auc: 0.5669\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 0.0746 - accuracy: 0.9697 - auc: 0.9970 - val_loss: 3.0110 - val_accuracy: 0.5150 - val_auc: 0.5748\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 5s 115ms/step - loss: 0.0735 - accuracy: 0.9699 - auc: 0.9971 - val_loss: 2.8876 - val_accuracy: 0.5215 - val_auc: 0.5735\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 5s 108ms/step - loss: 0.0721 - accuracy: 0.9704 - auc: 0.9973 - val_loss: 3.0878 - val_accuracy: 0.5029 - val_auc: 0.5685\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 5s 114ms/step - loss: 0.0723 - accuracy: 0.9699 - auc: 0.9972 - val_loss: 2.9459 - val_accuracy: 0.5236 - val_auc: 0.5730\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 5s 118ms/step - loss: 0.0711 - accuracy: 0.9703 - auc: 0.9972 - val_loss: 3.2727 - val_accuracy: 0.5029 - val_auc: 0.5729\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 5s 121ms/step - loss: 0.0700 - accuracy: 0.9701 - auc: 0.9974 - val_loss: 3.1266 - val_accuracy: 0.5150 - val_auc: 0.5703\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 5s 121ms/step - loss: 0.0690 - accuracy: 0.9697 - auc: 0.9974 - val_loss: 3.1594 - val_accuracy: 0.5143 - val_auc: 0.5702\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 6s 126ms/step - loss: 0.0678 - accuracy: 0.9706 - auc: 0.9976 - val_loss: 3.0228 - val_accuracy: 0.5229 - val_auc: 0.5686\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 5s 111ms/step - loss: 0.0684 - accuracy: 0.9710 - auc: 0.9974 - val_loss: 3.0047 - val_accuracy: 0.5294 - val_auc: 0.5711\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 5s 116ms/step - loss: 0.0674 - accuracy: 0.9712 - auc: 0.9975 - val_loss: 3.2175 - val_accuracy: 0.5165 - val_auc: 0.5725\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 6s 137ms/step - loss: 0.0660 - accuracy: 0.9713 - auc: 0.9975 - val_loss: 3.2127 - val_accuracy: 0.5165 - val_auc: 0.5688\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 5s 123ms/step - loss: 0.0658 - accuracy: 0.9704 - auc: 0.9975 - val_loss: 3.1457 - val_accuracy: 0.5265 - val_auc: 0.5722\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 6s 128ms/step - loss: 0.0662 - accuracy: 0.9708 - auc: 0.9974 - val_loss: 2.9179 - val_accuracy: 0.5415 - val_auc: 0.5697\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 6s 131ms/step - loss: 0.0640 - accuracy: 0.9722 - auc: 0.9976 - val_loss: 3.4069 - val_accuracy: 0.5107 - val_auc: 0.5728\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 6s 132ms/step - loss: 0.0636 - accuracy: 0.9726 - auc: 0.9976 - val_loss: 3.1667 - val_accuracy: 0.5287 - val_auc: 0.5709\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 6s 144ms/step - loss: 0.0638 - accuracy: 0.9724 - auc: 0.9975 - val_loss: 3.2221 - val_accuracy: 0.5337 - val_auc: 0.5699\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 6s 132ms/step - loss: 0.0624 - accuracy: 0.9712 - auc: 0.9979 - val_loss: 3.4277 - val_accuracy: 0.5086 - val_auc: 0.5721\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 6s 132ms/step - loss: 0.0627 - accuracy: 0.9715 - auc: 0.9976 - val_loss: 3.3734 - val_accuracy: 0.5201 - val_auc: 0.5689\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 6s 144ms/step - loss: 0.0619 - accuracy: 0.9713 - auc: 0.9976 - val_loss: 3.1490 - val_accuracy: 0.5423 - val_auc: 0.5705\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 6s 138ms/step - loss: 0.0615 - accuracy: 0.9728 - auc: 0.9976 - val_loss: 3.2787 - val_accuracy: 0.5279 - val_auc: 0.5712\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 6s 132ms/step - loss: 0.0606 - accuracy: 0.9728 - auc: 0.9976 - val_loss: 3.6044 - val_accuracy: 0.5172 - val_auc: 0.5717\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 6s 135ms/step - loss: 0.0599 - accuracy: 0.9737 - auc: 0.9978 - val_loss: 3.1918 - val_accuracy: 0.5401 - val_auc: 0.5704\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 6s 148ms/step - loss: 0.0591 - accuracy: 0.9729 - auc: 0.9978 - val_loss: 3.4390 - val_accuracy: 0.5258 - val_auc: 0.5667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1901120e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM ARCHITECTURE\n",
    "## Input layer\n",
    "input_layer = Input(\n",
    "    name=\"inputs\",\n",
    "    shape=[SEQUENCE_MAX_LEN])\n",
    "\n",
    "## Embedding layer: pre-trained embeddings\n",
    "layer = Embedding(\n",
    "    input_dim=len(processed_data[\"tokenizer\"].word_index)+1,\n",
    "    output_dim=SEQUENCE_MAX_LEN,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=MAX_N_WORDS,\n",
    "    trainable=False)(input_layer)\n",
    "\n",
    "## LSTM layer\n",
    "layer = LSTM(units=64)(layer)\n",
    "\n",
    "## Output layer\n",
    "layer = Dense(\n",
    "    name=\"output\",\n",
    "    units=1)(layer)\n",
    "\n",
    "## Activation layer\n",
    "output_layer = Activation(activation=\"sigmoid\")(layer)\n",
    "\n",
    "# CREATE A LSTM MODEL WITH THE PRIOR ARCHITECTURE\n",
    "## Model object\n",
    "lstm_model1 = Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=output_layer)\n",
    "\n",
    "## Summary of the model\n",
    "lstm_model1.summary()\n",
    "\n",
    "## Compile the model \n",
    "lstm_model1.compile(\n",
    "    loss=LOSS_FUNCTION,\n",
    "    optimizer=OPTIMIZER,\n",
    "    metrics=VALID_METRICS)\n",
    "\n",
    "# LSTM TRAINING\n",
    "## Train the prior built model\n",
    "lstm_model1.fit(\n",
    "    x=processed_data[\"train_matrix\"], \n",
    "    y=np.array(processed_data[\"train_labels\"]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=N_EPOCHS,\n",
    "    validation_split=VALID_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal y como se puede apreciar en los siguientes resultados, la tasa de aciertos sobre el conjunto de entrenamiento es bastante alta con un 88% aunque sobre el conjunto de **test apenas alcanza el 61% de accuracy**. Considerando el valor desmesurádamente bajo del área bajo la curva ROC en base al mismo conjunto de datos se puede concluir que la **capacidad de predicción del modelo apenas supera la de un clasificador aleatorio**. \n",
    "\n",
    "Observando la matriz de confusión es altamente notable la **elevada tasa de falsos negativos**, es decir, textos sexistas que no han sido detectados. Por lo tanto con una arquitectura LSTM básica y la mejor configuración encontrada en este grupo de experimentos, parece no ser suficiente precisa como para construir un clasificador de calidad capaz de identificar textos sexistas y no sexistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 4s 19ms/step - loss: 0.7335 - accuracy: 0.8848 - auc: 0.9197\n",
      "Accuracy over train dataset: 0.8847642540931702\n",
      "AUC over train dataset: 0.9196926355361938\n",
      "\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 2.5670 - accuracy: 0.6170 - auc: 0.6479\n",
      "Accuracy over test dataset: 0.6169871687889099\n",
      "AUC over test dataset: 0.6478633284568787\n",
      "137/137 [==============================] - 3s 19ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## LSTM VALIDATION\n",
    "## Evaluate the trained LSTM model over train and test datasets\n",
    "validate_lstm_model(\n",
    "    model=lstm_model1,\n",
    "    train_matrix=processed_data[\"train_matrix\"],\n",
    "    train_labels=processed_data[\"train_labels\"],\n",
    "    test_matrix=processed_data[\"test_matrix\"],\n",
    "    test_labels=processed_data[\"test_labels\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00f7dc61815a6da5453fee0a1d7c3baaa88d552412e55cf65ecdf10d17265d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
